---
title: "Exploratory Plots"
output:
  github_document: 
    toc: true
---

```{r setup, include=FALSE, message=FALSE}
library(targets)
library(knitr)
library(sf)
library(showtext)
library(tigris)
library(tidyverse)
library(GGally)
library(RColorBrewer)
library(gridExtra)
library(cowplot)

opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
opts_chunk$set(echo = FALSE, warning = FALSE, fig.width = 10, fig.height = 7)

font_add_google("Lato")
showtext_auto()

custom_theme <- function(...){
  theme_bw() + 
    theme(
      text = element_text(family = "Lato", size = 14),
      ...
    )
}

theme_set(custom_theme())
```

```{r}
# During interactive use, this chunk has to be loaded separately from the setup chunk.
# `targets` looks for a `_targets/` directory but cannot find one
# if the working directory is pointed at the `docs/` directory already, as is the
# case with Rmarkdown documents by default.

# The line starting with `opts_knit$set` above sets the correct working directory,
# but it only applies for chunks after the setup chunk, hence the separation of 
# the data load and the rest of the setup

# This is quite annoying workflow-wise, as the setup chunk is loaded automatically
# but this chunk isn't
mpeds_raw <- tar_read(canonical_events)
mpeds_sf <- tar_read(integrated) 
mpeds <- mpeds_sf |> st_drop_geometry()
```



# Basic counts

```{r, basic_counts, message = FALSE, warning = FALSE}
mpeds_raw_ids <- length(unique(mpeds_raw$canonical_id))
mpeds_ids <- length(unique(mpeds$canonical_id))
n_locations <- length(unique(mpeds$location))
n_counties <- mpeds |> 
  filter(str_detect(geoid, "^us_")) |> 
  pull(geoid) |> 
  unique() |> 
  length()
n_cmas <- mpeds |> 
  filter(str_detect(geoid, "^canada_")) |> 
  pull(geoid) |> 
  unique() |> 
  length()
n_universities <- length(unique(mpeds$university))

missing_unis <- mpeds$university_locations |>
  bind_rows() |>
  filter(is.na(lat), !is.na(location))
n_missing_uni_rows <- nrow(missing_unis)
n_missing_unis <- missing_unis$location |>
  unique() |> 
  length()

n_has_police <- mpeds |> 
  filter(!map_lgl(police_presence_and_size, is.null),
         !map_lgl(police_presence_and_size, ~all(. == "NA/Unclear"))
         ) |> 
  nrow()

n_has_police_activity <- mpeds |> 
  filter(!map_lgl(police_activities, is.null),
         !map_lgl(police_activities, ~all(. == "NA/Unclear"))
         ) |> 
  nrow()

police_only <- mpeds |> 
  filter(if_any(c(
    police_presence_and_size,
    police_activities,
    police_actions,
    type_of_police
  ), ~!map_lgl(.,\(x){is.null(x)}))) |>
  filter(if_any(c(
    police_presence_and_size, 
    police_activities,
    police_actions,
    type_of_police
  ), ~map_lgl(., \(x){any(x != "NA/Unclear")}))) 

n_any_police_field <- police_only |> 
  nrow()

n_both_pa_ur <- police_only |> 
  filter(if_any(c(
    university_action_on_issue,
    university_responses,
    university_reactions_to_protest,
    university_discourse_on_protest,
    university_discourse_on_issue
  ), ~!map_lgl(., function(x){
    is.null(x)
  }))) |> filter(if_any(c(
    university_action_on_issue,
    university_responses,
    university_reactions_to_protest,
    university_discourse_on_protest,
    university_discourse_on_issue
  ), ~map_lgl(., \(x){any(x != "NA/Unclear")}))) |> 
  nrow()

# only PA (any PA field)
# only UR (any UR field)
# no response (no recorded PA or UR field)

n_uni_police_only <- mpeds |> 
  filter(!map_lgl(type_of_police, is.null),
         map_lgl(type_of_police, function(x){
    all(x %in% c("Univ police", "Univ police - assumed"))
  })) |> 
  nrow()

n_govt_police_only <- mpeds |> 
  filter(!map_lgl(type_of_police, is.null),
         map_lgl(type_of_police, function(x){
    all(x %in% c("Govt police", "Govt police - assumed", '"Riot police"'))
  })) |> 
  nrow()

n_uni_and_govt_police <- mpeds |> 
  filter(!map_lgl(type_of_police, is.null),
         map_lgl(type_of_police, function(x){
    any(x %in% c("Univ police", "Univ police - assumed"))
         }),
         map_lgl(type_of_police, function(x){
    any(x %in% c("Govt police", "Govt police - assumed", '"Riot police"'))
         })
    ) |> 
  nrow()

mpeds_issues <- mpeds |> 
  select(key, issue, racial_issue) |> 
  pivot_longer(cols = c(issue, racial_issue)) |> 
  unnest(value) |> 
  filter(value != "_Not relevant") |> 
  group_by(key) |> 
  count()

# % with at least one issue, at least one racial issue
n_one_both_issue <- mpeds |> 
  select(key, issue, racial_issue) |> 
  pivot_longer(cols = c(issue, racial_issue)) |> 
  unnest(value) |> 
  filter(value != "_Not relevant") |> 
  select(key, name) |> 
  distinct() |> 
  count(key) |> 
  filter(n >= 2) |> 
  nrow()

# mode of issues per protests
# fun one code-wise
mode_issues <- mpeds_issues |> 
  group_by(n) |> 
  count() |> 
  ungroup() |> 
  arrange(desc(nn)) |> 
  slice_head(n = 1) |> 
  pull(n)

# mean of issues per protest
mean_issues <- round(mean(mpeds_issues$n), 2)

# % with only one issue
n_only_one_issue <- mpeds_issues |> 
  group_by(n) |> 
  count() |> 
  filter(n == 1) |> 
  pull(nn)
  
# events with lots of issues
mpeds_issues |> 
  arrange(desc(n)) |> 
  ungroup() |> 
  slice_head(n = 5) |> 
  rename("Events with many issues" = key,
         "Number of issues" = n) |> 
  kable()

tribble(
  ~Statistic, ~Value,
  "Total imported events", mpeds_raw_ids,
  "Total events after cleaning", mpeds_ids,
  "Unique locations", n_locations,
  "US counties", n_counties,
  "Canadian CMAs", n_cmas,
  "Universities", n_universities,
  "Missing universities", n_missing_unis,
  "CEs with missing universities", n_missing_uni_rows,
  "# of events with police activity recorded", n_has_police_activity,
  "# of events with any police field recorded", n_any_police_field,
  "# of events with university police only", n_uni_police_only,
  "# of events with government police only", n_govt_police_only,
  "# of events with both types of police", n_uni_and_govt_police,
  "# of events with at least one issue", n_one_both_issue,
  "mode of issue counts", mode_issues,
  "mean of issue counts", mean_issues,
  "# of events with just one issue", n_only_one_issue, 
) |> 
  kable()


```

The initial import of the MPEDS db found `r mpeds_raw_ids` 
unique canonical events, and after all cleaning steps we
still have `r mpeds_ids` canonical events.

However, there's still an issue regarding duplicate matches
in IPEDS we can detect (there are likely also incorrect matches that we can't
detect programmatically right now); there are lots of schools called
"Columbia College" (or another common name) inside IPEDS, so any schools with that name
in MPEDS will be assigned multiple schools. The MPEDS-IPEDS join
is crucial because we also use IPEDS to join county FIPS identifiers,
and thus no further joins will be accurate unless the MPEDS-IPEDS
join is accurate. As of Jan 30, 2023, we are in the middle of repairing
this join. 

Of those events, there were `r n_locations` unique locations, 
`r n_counties` unique counties, `r n_cmas` unique Canadian CMAs, and `r n_universities` unique universities.
Surprisingly, all of the locations that were not universities 
found geocoding matches, and hand-checking the most common ones indicates that
there isn't a strong pattern of missing value substitution, e.g. Google isn't
sending the majority of results  to the centroid of America or to `(-1, -1)` or 
anything weird like that. Universities had a harder time, with `r n_missing_unis`
universities and `r n_missing_uni_rows` rows (canonical events) not returning
lon/lat coords for universities. 

That comes out to ~5% of universities not having coordinates, and
~2.5% of canonical events not having universities with coordinates.

The top universities by appearances:

```{r university_counts}

university_counts <- mpeds |> 
  group_by(university) |> 
  count() |> 
  ungroup() |> 
  drop_na() |>
  slice_max(order_by = n, n = 15)

kable(university_counts)

```
And the top locations: 


```{r location_counts}
location_counts <- mpeds |> 
  group_by(location) |> 
  count() |> 
  ungroup() |> 
  drop_na() |> 
  slice_max(order_by = n, n = 15)

kable(location_counts)
```

Top states: 

```{r state_counts}

state_counts <- mpeds |> 
  group_by(area_name) |> 
  count() |> 
  ungroup() |> 
  drop_na() |> 
  slice_max(order_by = n, n = 15) 
  
kable(state_counts)

```

And finally the top counties:

```{r county_counts}

county_fips <- fips_codes |> 
  mutate(fips = paste0(state_code, county_code),
         county_name = paste0(county, ", ", state_name)) |> 
  select(fips, county_name)

county_counts <- mpeds |> 
  group_by(locality_name) |> 
  count() |> 
  ungroup() |> 
  drop_na() |> 
  slice_max(order_by = n, n = 15) 
  
kable(county_counts)

```

These glimpses seem mostly in line with what we should expect, with a strong
caveat that the Missouri protests are not making a leading appearance in the 
counts by location, but there do seem to be a fair number in Missouri when we
take a look by state. It seems there are non-MO locations being recognized as
happening in Missouri. See our 1:1 notes Google Doc for details.

```{r police_counts}
# God that was hard
glimpse_counts <- function(colname){
  mpeds |>
    mutate("{{ colname }}" := map({{ colname }}, \(item){
      if(is.null(item)){
        return(NA)
      }
      return(str_replace_all(item, "\n", " "))
      })) |>
    select({{colname}}) |> 
    unnest(cols = {{colname}}) |> 
    group_by({{ colname }}) |> 
    count({{ colname }}) |> 
    arrange(desc(n)) |> 
    kable()
}

glimpse_counts(police_presence_and_size)
glimpse_counts(police_activities)
glimpse_counts(type_of_police)
```

```{r university_responses_counts}
glimpse_counts(university_action_on_issue)
glimpse_counts(university_discourse_on_issue)
glimpse_counts(university_reactions_to_protest)
```

"NA" marks canonical events where issues were not assigned at all, or where
text-selects were used but not one of the preset issue categories. "_Not relevant"
*should* be marked when a racial issue was selected instead, per the codebook.
"_Other issue" marks issues not within the preset options; the codebook gives the
examples of:

- protestors who use hateful speech, e.g. anti-LGBTQ preachers
- (objection to?) corporate practices
- access to higher education (?)
- science (?)
- Armenian genocide (?)

Hm. 

## Counts by issue

```{r}
glimpse_counts(issue)
```

## Counts by racial issue:

```{r}
glimpse_counts(racial_issue)
```

# Police involvement by issue

We're interested in describing police involvement by issue -- what issues attract
the heaviest police presence and response? 

I filtered our dataset to include only rows that had at least one non-missing value
for type of police, police actions, police activities, and police presence and size,
and tabulated the issues reported in the remaining dataset. The table can 
thus be read as the most popular issues among police-involved protests.

In the table below, counts may be inflated given each canonical event could have
multiple issues. 

This table should be compared to the table of percentages of issues across all events
to be meaningful for the questions we'd like to answer. For example, university
governance makes a strong appearance here, but that could be just because it is 
a popular issue at large, not because protests around the issue attract police.
On the other hand, tuition and fees makes a solid jump here from having 10% 
prevalence across all events but with 16% prevalence across police-involved events.
This makes sense given our knowledge that the Quebec tuition strike protests
were heavily policed.

```{r police_involvement_by_issue}
police_involvement <- mpeds |> 
  filter(
    if_any(c(type_of_police, police_actions,
          police_activities, police_presence_and_size),
        ~map_lgl(., \(x){!is.null(x)})),
    if_any(c(type_of_police, police_actions,
          police_activities, police_presence_and_size),
        ~map_lgl(., \(x){any(x != "NA/Unclear")})),
    ) 

get_issue <- function(dta){
  dta |> 
    select(issue, racial_issue) |> 
    pivot_longer(cols = c(issue, racial_issue)) |> 
    unnest(cols = value) |> 
    filter(value != "_Not relevant") |> 
    drop_na() |> 
    mutate(value = ifelse(
      name == "racial_issue", paste(value, "(racial)"), value)
      ) |> 
    select(-name) |> 
    group_by(value) |> 
    count() |> 
    ungroup() |> 
    mutate(n = round(100 * n/length(unique(dta$canonical_id)), 2)) |> 
    arrange(desc(n)) 
}

police_involvement_issue <- get_issue(police_involvement)
police_involvement_issue |> 
  rename(
    "Issue" = value,
    "Percent of events with given issue" = n
  ) |> 
  kable()
top_police_issues <- police_involvement_issue |> 
  slice_max(order_by = n, n = 7)

extreme_police_issue <- mpeds |> 
  filter(map_lgl(police_activities, 
                 ~any(c("Arrest- Large Scale", "Force: 2+ Weapon Types") %in%
                       .)) | 
           map_lgl(police_presence_and_size,
                   ~any(c("Heavily Policed", "Motorized Presence", 
                          "Substantial") %in% .)) | 
           map_lgl(type_of_police, 
                   ~('"Riot police"' %in% .))) |> 
  get_issue()
top_extreme_police_issue <- extreme_police_issue |> 
  slice_max(order_by = n, n = 7)

mpeds_police_issue <- get_issue(mpeds)

plot_comparison <- function(dta, name){
  dta <- list("All protests" = mpeds_police_issue,
       "category" = dta) |> 
    bind_rows(.id = "type") |> 
    mutate(type = ifelse(type == "category",
                         str_to_sentence(name),
                         type)) |> 
    filter(value %in% dta$value) |> 
    mutate(value = str_wrap(value, 15),
           value = factor(value, levels = str_wrap(dta$value, 15))) 
  
  diffs <- dta |> 
    group_by(value) |> 
    mutate(diff = round(2*n - sum(n), 2),
           diff = ifelse(type == "All protests", NA, diff),
           diff = ifelse(diff > 0, paste0("+", diff), paste0("-", diff))) |> 
    select(type, value, diff)
  
  dta |> 
    left_join(diffs, by = c("value", "type")) |> 
    ggplot(aes(x = value, fill = value, y = n)) + 
    geom_bar(stat = "identity") + 
    geom_text(aes(label = diff), vjust = -0.5) +
    facet_wrap(~type, nrow = 2) + 
    labs(
      title = paste0("Top issue occurrences in ", name, " and general protests"),
      y = "Percentage of protests associated with issues",
      x = NULL,
      caption = str_wrap(paste0(
        "Top issues are defined as the seven most common issues for ", 
        name, ". Difference from corresponding measure for all protests are labeled for ",
        name, "."), 110)
    ) + 
    scale_fill_brewer(type = "qual", palette = "Set1") + 
    scale_y_continuous(breaks = seq(0, 35, by = 5), limits = c(0, 33)) + 
    theme(legend.position = "none")
}

plot_comparison(top_police_issues, "police-involved protests")
plot_comparison(top_extreme_police_issue, "protests with extreme policing")
```
  


# Percentages of all protest with given preset

```{r}
get_percent <- function(colname){
  n_total <- length(unique(mpeds$canonical_id))
  pct_any <- mpeds |> 
    filter(!({{colname}} %in% c("_Not relevant", "")),
           map_lgl({{colname}}, ~!is.null(.)))
  mpeds |>
    mutate("{{ colname }}" := map({{ colname }}, \(item){
      if(is.null(item)){
        return(NA)
      }
      return(str_replace_all(item, "\n", " "))
      })) |>
    select({{colname}}) |> 
    unnest(cols = {{colname}}) |> 
    group_by({{ colname }}) |> 
    count({{ colname }}) |> 
    mutate(pct = round(100 * n / n_total, 2)) |> 
    select(-n) |> 
    bind_rows(tibble({{colname}} := "Percent of events with any value",
                     pct = round(100 * nrow(pct_any) / n_total, 2))) |> 
    arrange(desc(pct)) |> 
    kable()
}

get_percent(issue)
get_percent(racial_issue)
```

# Counts over time

```{r basic_counts_over_time, width = 12, height = 8}

summer_color <- "#ff4b3a"
events_color <- "#2133ff"

summers <- tibble(
  x1 = seq(as.Date("2012-06-01"), as.Date("2018-06-01"), by = "1 year"),
  x2 = seq(as.Date("2012-08-31"), as.Date("2018-08-31"), by = "1 year"),
  y1 = -100,
  y2 = 400
)

mpeds |> 
  mutate(date = floor_date(start_date, "month")) |> 
  group_by(date) |> 
  count() |> 
  drop_na() |> 
  ggplot() +
  geom_rect(data = summers, aes(xmin = x1, xmax = x2, ymin = y1, ymax = y2), 
            alpha = 0.1,
            color = NA, fill = summer_color) +
  geom_line(aes(x = date, y = n)) +
  scale_y_continuous(breaks = seq(0, 400, by = 50),
                     ) + 
  scale_x_date(date_breaks = "6 months",
               date_labels = "%b %y",
               guide = guide_axis(n.dodge = 2)) + 
  geom_vline(xintercept = as.Date("2012-02-01"), color = events_color) +
  annotate(geom = "label", label = "Quebec\nprotests",
           color = events_color, x = as.Date("2012-06-01"), y = 300,
           family = "Lato") + 
  
  geom_vline(xintercept = as.Date("2015-08-01"), color = events_color) +
  annotate(geom = "label", label = "Darren Wilson\nindictment",
           color = events_color, x = as.Date("2015-02-01"), y = 275,
           family = "Lato") + 
  
  geom_vline(xintercept = as.Date("2015-10-01"), color = events_color) +
  annotate(geom = "label", label = "Mizzou\nprotests",
           color = events_color, x = as.Date("2016-02-01"), y = 325,
           family = "Lato") + 
  
  geom_vline(xintercept = as.Date("2017-02-01"), color = events_color) +
  annotate(geom = "label", label = "Anti-Trump\nprotests",
           color = events_color, x = as.Date("2017-07-01"), y = 300,
           family = "Lato") + 
           
  coord_cartesian(expand = FALSE, ylim = c(0, 400),
                  xlim = c(as.Date("2011-12-02"), as.Date("2018-12-31"))) + 
  labs(
    title = "Counts of protest events over time",
    x = NULL,
    y = "Number of associated events",
    caption = str_wrap("Dates are aggregated to months. Segments in red indicate summers.")
  ) 

```

```{r basic_counts_time_redux, fig.height = 10, fig.width = 7}

plots <- map(2012:2018, function(yr){
  mpeds |> 
    mutate(date = floor_date(start_date, "month")) |> 
    filter(lubridate::year(date) == yr) |> 
    group_by(date) |> 
    count() |> 
    drop_na() |> 
    ggplot(aes(x = date, y = n)) + 
    geom_line() + 
    labs(y = NULL, x = NULL, title = yr) + 
    scale_y_continuous(limits = c(0, 400)) +
    scale_x_date(date_labels = "%b", date_breaks = "2 months") + 
    theme(
      plot.title = element_text(size = 11),
      axis.text.x = if(yr == 2018){element_text()}else {element_blank()}
      )
})
title_grob <- ggdraw() + 
  draw_label("Counts of canonical events over time",
             x = 0.05, 
             hjust = 0, 
             fontfamily = "Lato",
             fontface = "bold"
            ) +
  theme(plot.margin = unit(c(0, 0, 0, 0), "cm"))
plot_grid(title_grob, plotlist = plots, ncol = 1)

```


```{r regions_over_time}
protests_by_region <- mpeds |> 
  mutate(region = case_when(
    str_detect(geoid, "^canada_") ~ paste(region_name, "(CA)"),
    is.na(region_name) ~ NA_character_,
    TRUE ~ region_name)
    ) |> 
  mutate(date = floor_date(start_date, "month"),
         region = as_factor(region) |> 
           fct_reorder(ifelse(!str_detect(geoid, "^canada_"), 0, 1))) |> 
  group_by(region, date) |> 
  count() |> 
  drop_na() 

protests_region_plot <- ggplot(protests_by_region,
       aes(fill = region, x = date, y = n)) + 
  geom_bar(stat = "identity") + 
  scale_x_date(breaks = "4 months",
               date_labels =  "%b",
               sec.axis = dup_axis(
                 breaks = seq(as.Date("2012-01-01"), as.Date("2018-01-01"), by = "year"),
                 labels = scales::label_date("%Y"),
               )
               ) + 
  scale_fill_brewer(type = "qual", palette = "Set1") + 
  labs(
    title = "Events over time by region",
    x = "Date (floored to months)",
    y = "Number of associated canonical events", 
    color = "U.S. Census region,\nor Canadian province"
  ) 

protests_region_plot

```

```{r regions_time_vert, fig.height = 10, fig.width = 8}

plots <- map(2012:2018, function(yr){
  protests_by_region |> 
    filter(lubridate::year(date) == yr) |> 
    ggplot(aes(fill = region, x = date, y = n)) + 
    geom_bar(stat = "identity") + 
    labs(y = NULL, x = NULL, title = yr) + 
    # scale_y_continuous(limits = c(0, 400)) +
    scale_x_date(date_labels = "%b", date_breaks = "2 months") + 
    scale_fill_brewer(type = "qual", palette = "Set1") + 
    theme(
      legend.position = "none",
      plot.title = element_text(size = 11),
      axis.text.x = if(yr == 2018){element_text()}else {element_blank()}
      )
})

get_legend<-function(gg){
  tmp <- ggplot_gtable(ggplot_build(gg))
  leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
  legend <- tmp$grobs[[leg]]
  return(legend)
}

legend_grob <- get_legend(protests_region_plot +
                            labs(fill = NULL) + 
                            theme(legend.position = "bottom")
                          )

title_grob <- ggdraw() + 
  draw_label("Counts of canonical events over time by region",
             x = 0.05, 
             hjust = 0, 
             fontfamily = "Lato",
             fontface = "bold"
            ) +
  theme(plot.margin = unit(c(0, 0, 0, 0), "cm"))

plot_grid(title_grob, plotlist = plots, legend_grob, ncol = 1)

```

```{r over_time_country}

protests_by_country <- mpeds |> 
  mutate(
    country = ifelse(
      str_detect(geoid, "us_"), "United States", "Canada"
    )
    ) |> 
  mutate(date = floor_date(start_date, "month")) |> 
  group_by(country, date) |> 
  count() |> 
  drop_na() 

ggplot(protests_by_country, aes(fill = country, x = date, y = n)) + 
  geom_bar(stat = "identity") + 
  scale_fill_brewer(type = "qual", palette = "Set1") + 
  scale_x_date(date_breaks = "6 months",
               date_labels = "%b %y",
               guide = guide_axis(n.dodge = 2)) + 
  labs(
    y = "Number of associated canonical events",
    x = "Date (floored to months)",
    fill = "Country",
    title = "Canonical events by country"
  ) 
```

We can also begin to look at the top universities, counties, locations, or states
over time. This inevitably produces more complex summaries, and it can
be difficult to take an informative glimpse given so many categories, so I've only
shown the universities over time for now:

```{r unis_over_time}
uni_grouping <- tribble(
  ~university, ~group,
  "Columbia University in the City of New York", "Northeast",
  "Harvard University", "Northeast",
  "Tufts University", "Northeast",
  "Concordia University",  "Quebec",
  "McGill University", "Quebec",
  "University of Toronto", "Ontario",
  "Ryerson University", "Ontario",
  "University of California-Berkeley", "California",
  "University of California-Los Angeles", "California",
  "University of Chicago", "Midwest",
  "University of Michigan-Ann Arbor", "Midwest",
  "University of Wisconsin-Madison", "Midwest"
)

unis_over_time <- mpeds |> 
  mutate(date = floor_date(start_date, "month")) |> 
  group_by(university, date) |> 
  count() |> 
  drop_na() |> 
  filter(university %in% university_counts$university[1:10]) |> 
  mutate(university = str_wrap(university, 15)) |> 
  left_join(uni_grouping, by = "university")

uni_plot <- ggplot(unis_over_time, aes(x = date, y = n, fill = university)) + 
  geom_bar(stat = "identity") + 
  scale_fill_brewer(type = "qual", palette = "Paired") + 
  labs(
    x = paste0("Time (months)"),
    y = "Number of associated canonical events",
    title = "Top universities by protest count over time",
    caption = paste("Universities displayed are top 10 overall universities
    by protest count, not a top university in a given year.", 
    "Dates are aggregated to the month unit.")
  ) + 
  guides(fill = guide_legend(byrow = TRUE)) + 
  theme(legend.spacing.y = unit(0.2, "cm")) + 
  scale_x_date(breaks = "4 months",
               date_labels =  "%b",
               sec.axis = dup_axis(
                 breaks = seq(as.Date("2012-01-01"), as.Date("2018-01-01"), by = "year"),
                 labels = scales::label_date("%Y"),
               )
               )
  
uni_plot

uni_grouping_over_time <- mpeds |> 
  mutate(date = floor_date(start_date, "month")) |> 
  filter(university %in% university_counts$university[1:10]) |> 
  left_join(uni_grouping, by = "university") |> 
  group_by(group, date) |> 
  count() |> 
  drop_na() 

uni_grouped_plot <- ggplot(uni_grouping_over_time, aes(x = date, y = n, fill = group)) + 
  geom_bar(stat = "identity") + 
  scale_fill_brewer(type = "qual", palette = "Set1") + 
  scale_x_date(breaks = "4 months",
               date_labels =  "%b",
               sec.axis = dup_axis(
                 breaks = seq(as.Date("2012-01-01"), as.Date("2018-01-01"), by = "year"),
                 labels = scales::label_date("%Y"),
               )
               ) + 
  labs(
    x = paste0("Time (floored to months)"),
    y = "Number of associated canonical events",
    title = "Top university groups by protest count over time",
    caption = paste("Dates are aggregated to the month unit.")
  ) 

uni_grouped_plot
```


```{r responses_over_time}
plot_response_over_time <- function(colname){
  unnested <- mpeds |>
    mutate("{{ colname }}" := map({{ colname }}, \(item){
      if(is.null(item)){
        return(NA)
      }
      return(item)
      })) |>
    select(start_date, {{colname}}) |> 
    unnest(cols = {{colname}}) |> 
    filter(!is.na({{colname}}), {{colname}} != "NA/Unclear")
  
  top_overall <- unnested |> 
    count({{colname}}) |> 
    arrange(desc(n)) |> 
    slice(1:9) |> 
    pull({{colname}}) 
  
  name_string <- rlang::as_name(enquo(colname)) |> 
    str_replace_all("_", " ") |> 
    str_to_sentence() 
  
  unnested |> 
    filter({{colname}} %in% top_overall) |> 
    mutate(date = floor_date(start_date, "month")) |> 
    group_by({{colname}}, date) |> 
    count() |> 
    ggplot(aes(x = date, y = n, fill = {{colname}})) + 
    geom_bar(stat = "identity") + 
    scale_fill_brewer(type = "qual", palette = "Paired") + scale_x_date(breaks = "4 months",
               date_labels =  "%b",
               sec.axis = dup_axis(
                 breaks = seq(as.Date("2012-01-01"), as.Date("2018-01-01"), by = "year"),
                 labels = scales::label_date("%Y"),
               )
               ) + 
    scale_x_date(breaks = "4 months",
               date_labels =  "%b",
               sec.axis = dup_axis(
                 breaks = seq(as.Date("2012-01-01"), as.Date("2018-01-01"), by = "year"),
                 labels = scales::label_date("%Y"),
               )
               ) + 
    labs(
      title = paste(name_string, "over time"),
      y = "Number of occurrences",
      x = "Date (month)",
      fill = name_string
    ) +
    guides(fill = guide_legend(byrow = TRUE)) +
    theme(
      legend.spacing.y = unit(0.2, "cm")
    )
}

plot_response_over_time(police_presence_and_size)
plot_response_over_time(police_activities)
plot_response_over_time(type_of_police)
plot_response_over_time(university_action_on_issue)
plot_response_over_time(university_discourse_on_issue)
plot_response_over_time(university_reactions_to_protest)
```

```{r issues_over_time}
# Tad tricky since there are often multiple issues per role
issues <- mpeds |> 
  select(issue, start_date) |> 
  unnest(cols = issue) |> 
  mutate(date = floor_date(start_date, "month"),
         issue = str_wrap(issue, 20),
         ) |> 
  filter(issue != "_Not relevant")

racial_issue <- mpeds |> 
  select(issue = racial_issue, start_date) |> 
  unnest(cols = issue) |> 
  mutate(date = floor_date(start_date, "month"),
         issue = str_wrap(issue, 20),
         ) |> 
  filter(issue != "_Not relevant")

# 42 rows is still readable so I'll just print the entire table
issues_count <- issues |> 
  count(issue) |> 
  arrange(desc(n)) 

racial_issue_count <- racial_issue |> 
  count(racial_issue = issue) |> 
  arrange(desc(n))

racial_issue_count |> 
  mutate(racial_issue = str_replace_all(racial_issue, "\n", ' ')) |> 
  kable()

top_racial_issues <- racial_issue |> 
  filter(issue %in% racial_issue_count$racial_issue[1:4]) |> 
  mutate(issue = paste(issue, "(racial)"))


# 42 lines on a plot on the other hand is like 35 too many
issues |> 
  filter(issue %in% issues_count$issue[1:7]) |> 
  group_by(issue, date) |> 
  count() |> 
  drop_na() |> 
  ggplot(aes(x = date, y = n, fill = issue)) + 
  geom_bar(stat = "identity") + 
  scale_fill_brewer(type = "qual", palette = "Set1") + 
  scale_x_date(breaks = "4 months",
             date_labels =  "%b",
             sec.axis = dup_axis(
               breaks = seq(as.Date("2012-01-01"), as.Date("2018-01-01"), by = "year"),
               labels = scales::label_date("%Y"),
             )
             ) + 
  labs(
    title = "Issue breakdown over time",
    y = "Number of associated canonical events",
    x = "Date (month)",
    caption = "Excludes racial issues."
  ) +
  guides(fill = guide_legend(byrow = TRUE)) +
  theme(
    legend.spacing.y = unit(0.5, "cm")
  )
  
issues |>
  filter(issue %in% issues_count$issue[1:4]) |> 
  bind_rows(top_racial_issues) |> 
  mutate(issue = as.factor(issue) |> 
           fct_relevel(c(
             issues_count$issue[1:4],
             racial_issue_count$racial_issue[1:4])
             )) |> 
  group_by(issue, date) |> 
  count() |> 
  drop_na() |> 
  ggplot(aes(x = date, y = n, fill = issue)) + 
  geom_bar(stat = "identity") + 
  scale_fill_brewer(type = "qual", palette = "Set1") + 
  labs(
    title = "Issue breakdown over time",
    y = "Number of associated canonical events",
    x = "Date (month)",
    caption = "Includes racial issues."
  ) +
  guides(fill = guide_legend(byrow = TRUE)) +
  theme(
    legend.spacing.y = unit(0.5, "cm")
  )
  

# one where y-axis percentage of total issues in given month
# We want to divide the number of CEs associated with an issue in a month
# by the total number of CEs in a month; that latter statistic we have to get by 
# using `mutate` instead of `summarize` in order to preserve the tibble format, 
# but that means that the resulting column of counts will be duplicated,
# as in we'll have one count of total issues for each issue occurrence in a month
# I use `n_events1]` to resolve that
issues |> 
  group_by(date) |> 
  mutate(
    n_events = n()
  ) |> 
  group_by(issue, date)  |> 
  summarize(
    issue_pct = n() / n_events[1],
    .groups = "drop"
  ) |> 
  filter(issue %in% issues_count$issue[1:7]) |> 
  mutate(issue = fct_relevel(issue, issues_count$issue[1:7])) |> 
  ggplot(aes(x = date, y = issue_pct, fill = issue)) + 
  geom_bar(stat = "identity") + 
  scale_fill_brewer(type = "qual", palette = "Set1") + 
  labs(
    title = "Most common issues over time",
    caption = "Bars don't add up to 1.00 because I selected the top issues for display.
    42 issues in total is difficult to present."
  )
```

## Racial and "nonracial" issues over time (collapsed)

```{r}

# Separate cases required because of the way R checks for types and length
has_issue <- function(list_item){
  if(is.null(list_item)){
    return(FALSE)
  }
  if(length(list_item) == 1){
    return(list_item != "_Not relevant") 
  } else {
    return(TRUE)
  }
}

# Assembling issues and racial issues into one plot
mpeds |> 
  filter(!map_lgl(racial_issue, is.null),
         !map_lgl(issue, is.null)) |> 
  mutate(`Racial issue` = map_lgl(racial_issue, has_issue),
         `Nonracial issue` = map_lgl(issue, has_issue),
         date = floor_date(start_date, "1 month"))  |> 
  select(`Nonracial issue`, `Racial issue`, date) |> 
  pivot_longer(cols = c(`Nonracial issue`, `Racial issue`),
               names_to = "type") |> 
  mutate(type = fct_relevel(
    type, "Racial issue", "Nonracial issue"
    )) |> 
  filter(value) |>
  group_by(date, type) |> 
  count() |> 
  ggplot(aes(x = date, y = n, fill = type)) + 
  geom_bar(stat = "identity") +
  labs(
    y = "Number of associated canonical events",
    x = "Date (floored to months)",
    title = "Racial and `non-racial` issues over time"
  ) + 
  scale_fill_brewer(type = "qual", palette = "Set1") 

mpeds |> 
  mutate(
    has_racial = map_lgl(racial_issue, has_issue),
    has_issue = map_lgl(issue, has_issue),
    category = case_when(
      has_issue & has_racial ~ "Has both",
      has_issue ~ "Non-racial issue",
      has_racial ~ "Racial issue",
      TRUE ~ "No issue assigned"
    ),
    category = fct_relevel(category, "Racial issue", 
                           "Non-racial issue", "Has both",
                           "No issue assigned"),
    date = floor_date(start_date, "1 month"))  |> 
  ggplot(aes(x = date, fill = category)) + 
  geom_bar() + 
  labs(
    x = NULL,
    fill = NULL,
    y = "Number of associated canonical events",
    title = "Protest counts by type of issue over time",
  ) +
  scale_fill_brewer(type = "qual", palette = "Set1") 

mpeds |>   
  filter(!map_lgl(racial_issue, is.null),
         !map_lgl(issue, is.null)) |> 
  mutate(`Racial issue` = map_lgl(racial_issue, has_issue),
         `Nonracial issue` = map_lgl(issue, has_issue),
         date = floor_date(start_date, "1 month"))  |> 
  select(`Nonracial issue`, `Racial issue`, date) |> 
  pivot_longer(cols = c(`Nonracial issue`, `Racial issue`),
               names_to = "type") |> 
  mutate(type = fct_relevel(
    type, "Racial issue", "Nonracial issue"
    )) |> 
  filter(value) |>
  group_by(date, type) |> 
  count() |> 
  group_by(date) |> 
  mutate(pct = n / sum(n)) |> 
  ggplot(aes(x = date, y = pct, fill = type)) + 
  geom_bar(stat = "identity") +
  labs(
    y = "Share of canonical events during given month",
    x = "Date (floored to months)",
    title = "Proportion of racial and `non-racial` issues over time"
  ) +
  scale_fill_brewer(type = "qual", palette = "Set1") 
  
```

I've collapsed both types of issues here to show racial and nonracial issues 
alongside each other. Racial issue counts here are taken at a maximum of one per 
canonical event, so that events that relate to many issues do not outweight others
and we have a clearer understanding of the weight of protest occurrence.
The same goes for nonracial issues. 

# Basic summary plots by variable

```{r summary}
mpeds |> 
  select(where(function(x){is.numeric(x) || is.logical(x)}),
                 -canonical_id, -starts_with("location"),
                 -year, -uni_id, -size_category, -link) |> 
  pivot_longer(cols = everything()) |> 
  filter(name != "NA") |> 
  group_by(name) |> 
  summarize(
    type = ifelse(is.numeric(pull(mpeds[name[1]], 1)), "numeric", "boolean"),
    mean = mean(value, na.rm = TRUE),
    sd = ifelse(type == "boolean", NA_integer_, sd(value, na.rm = TRUE))
  ) |> 
  mutate(across(where(is.numeric), ~round(., 3))) |> 
  arrange(type) |> 
  kable()
```

For boolean variables, "mean" is the proportion that they are TRUE. Many of the
variables recorded in MPEDS allowed for the input of multiple values, 
so those are handled as list-cols and not shown here.

```{r pairs, warning = FALSE, width = 8, height = 8}
mpeds |> 
  select(where(is.numeric), -canonical_id, -starts_with("location"),
                 -year, -uni_id, -size_category, -enrollment_count) |> 
  ggpairs(progress = FALSE, lower = list(
    continuous = wrap(ggally_points, size = 0.1, alpha = 0.2)
    ),
    title = "Glimpse at relationships among numeric variables"
    )

```

The pairs plot is still very difficult to read after adjustments. This should be
treated as a glimpse or overview, and more detailed and cleaner plots will be made
later on.

```{r distributions}
mpeds |> 
  select(where(is.numeric), -canonical_id, -starts_with("location"),
                 -year, -uni_id, -size_category) |> 
  pivot_longer(everything()) |> 
  drop_na() |> 
  ggplot(aes(value)) + 
  geom_histogram() + 
  facet_wrap(~name, scales = "free") + 
  labs(
    title = "Glimpse of numeric covariates at the canonical event level",
    y = "Number of occurrences",
    x = "Value of variable",
  )

```

# Trying out joins with protest data

To recap from our last conversation, it's a bit difficult to join the CCC data
and our data since a lot of MPEDS data points could presumably be in the CCC
records. Then CCC data could be telling us that there was a protest in the same
county, when it could just be talking about the same protest in MPEDS and
essentially be turning data quality into another covariate. 

We discussed two solutions to this problem to avoid deduplication:

- Join so that CCC protests occurring one, three, five, or seven days before the
  MPEDS protest date are matched; the CCC variable then conceptually becomes 
  "was there a recent protest in the same county." Thus protests won't find
  a match only because of duplicates
- Join only after filtering the CCC dataset so that rows with keywords related
  to universities are kicked out -- things like teachers, faculty, students,
  colleges, universities. This is less ideal than the above strategy because it
  is so nonspecific, potentially missing many university matches and kicking out
  protests related to primary and secondary schools.
  
The following chunk gives a glimpse at total number of matches:

```{r external_protest_sources}
ccc <- tar_read(ccc) |> 
  distinct() |> 
  rename(protest_date = ccc_protest_date)

blm <- tar_read(elephrame_blm) |> 
  distinct() |> 
  rename(protest_date = blm_protest_date)
  
# We want to assess successful match rates in a sensible manner, which means 
# restricting the MPEDS dataset to just the protest years available in either 
# CCC or Elephrame
n_ccc <- mpeds |> 
  filter(start_date > min(ccc$protest_date, na.rm = TRUE)) |> 
  nrow()
n_elephrame <- mpeds |> 
  filter(start_date > min(blm$protest_date, na.rm = TRUE)) |> 
  nrow()

test_date_diffs <- function(protests){
  # a version where dates are a list-col, to assist in the testing below
  protest_dates <- protests |> 
    group_by(fips) |> 
    summarize(recent_protest_dates_lst = list(protest_date))
  matched_mpeds <- mpeds |> 
    left_join(protest_dates, by = c("geoid" = "fips"))
  
  # return a TRUE value if any protests in `vec` occurred between 
  # a given date and `diff` days after that date
  compute_protests <- function(vec, date, diff){
    if(is.na(date)) return(NA)
    any(vec %in% (date + 1):(diff + date))
  }
  
  match_date_diff <- function(diff){
    # For each canonical event, use the `recent_protest_dates_lst` column
    # representing protests in the same county to assess if any
    # those nearby protests happened recently
    recent_protests <- matched_mpeds |> 
      mutate(
        has_recent_protest_nearby = unlist(map2(
          recent_protest_dates_lst, start_date,
          function(x,y){compute_protests(x, y, diff)}
        ))
      )
    
    n_matches <- sum(recent_protests$has_recent_protest_nearby, na.rm = TRUE)
    
    tribble(~date_offset, ~recent_protests,
            diff, n_matches, 
            )
    
  }
  return(map_dfr(c(0,1,3,5,7), match_date_diff))
}

match_results <- map_dfr(list("CCC" = ccc, "Elephrame" = blm),
                         test_date_diffs, .id = "source") |> 
  mutate(match_percentage = ifelse(
    source == "CCC", 100 * recent_protests / n_ccc,
    100 * recent_protests / n_elephrame
  ))

kable(match_results)

```

Here, the `match_percentage` column indicates how many canonical events saw another
protest occur in the same county within `diff` days, according to the dataset
in `source`. The fact that the match rate for 0 is much higher than 1 for both
Elephrame and CCC indicates that there is some double-counting of protests;
rather than multiple protests occurring concurrently, we may have recorded a protest
in our dataset that is also present in another dataset.

So it seems that there are a fair number of duplicates occurring if we don't
have a date offset, but once we add one (of any days) that pretty much solves
the data quality issue.

That being said, the likely larger problem with the CCC data is that it's only 
available after 2017, so it may not be relevant even after we become satisfied
with the deduped match process. This can be refined a little bit by adding in 
Elephrame data on BLM protests, but we've had problems there already, and the topic 
differences mean we can't pretend we have complete data.

# Maps and related things

```{r maps, message = FALSE, warning = FALSE}
state_sf <- states(progress_bar = FALSE) |> 
  filter(!(NAME %in% c("Hawaii", "Puerto Rico", "American Samoa", 
                       "United States Virgin Islands", 
                       "Commonwealth of the Northern Mariana Islands",
                       "Alaska", "Guam"))) |> 
  select(state_fips = GEOID)
us_sf <- nation()
```

```{r mpeds_map}

mpeds_sf |> 
  st_transform(st_crs(us_sf)) |>
  mutate(geometry = st_jitter(geometry, factor = 0.005)) |> 
  ggplot() + 
  geom_sf(data = us_sf, fill = "white", color = "gray") + 
  geom_sf(size = 0.1, alpha = 0.2) + 
  lims(
    x = c(-130, -60),
    y = c(20, 55)
  ) +
  labs(
    title = "Spread of canonical events and geocoded locations",
    subtitle = "Locations jittered slightly, by 0.005*bounding box diagonal.",
    caption = "Alaska, Hawaii, a few other locations with only a\nfew protests excluded in this map only."
  ) + 
  theme_void() + 
  theme(text = element_text(family = "Lato"),
        plot.title = element_text(size = 20))
```

# Investigating specific movements

## 2015 Mizzou protests

```{r mizzou, warning = FALSE}
tar_load(canonical_event_relationship)
# the `canonical_event_relationship` data.frame doesn't expose at first glance
# children-of-children, so we have to loop through the dataset until 
# we know we've found all of the sub-campaign events
mizzou_ids <- mpeds |>
  filter(key == "Umbrella_Mizzou_Anti-Racism_2015_Oct-Nov") |> 
  pull(canonical_id)

new_ids <- mizzou_ids
should_find_events <- TRUE
while(should_find_events){
  new_events <- tibble(canonical_id2 = new_ids) |> 
    inner_join(canonical_event_relationship, by = c("canonical_id2"))
  new_ids <- new_events$canonical_id1
  mizzou_ids <- c(mizzou_ids, new_ids)
  if(length(new_ids) == 0){
    should_find_events <- FALSE
  }
}
mizzou_ids <- unique(mizzou_ids)

mizzou_events <- canonical_event_relationship |> 
  filter(canonical_id2 %in% mizzou_ids | 
         canonical_id1 %in% mizzou_ids) 
  
mizzou_by_type <- mizzou_events |> 
  mutate(relationship_type = paste0(str_to_title(relationship_type), " events only")) |> 
  count(stat = relationship_type) 
  
tribble(~stat, ~n,
        "Total number of links", nrow(mizzou_events),
        "Unique events", length(unique(mizzou_events$canonical_id1))) |> 
  bind_rows(mizzou_by_type) |> 
  rename("Statistics for Mizzou protests" = stat) |> 
  kable()
```

The discrepancy between the total number of links from the original Mizzou event to the 
total number of unique events comes from some events being both campaign events and 
counterprotest events, or campaign events and solidarity events. 

```{r mizzou_map}
tar_load(geo)
tar_load(canada_province_shapes)

mizzou_sf <- tibble(canonical_id = mizzou_ids) |> 
  # joining on `mpeds` and not `mpeds_sf` because we want coords of counties/CMAs,
  # not exactly where protests occurred (which is more granular)
  left_join(mpeds, by = "canonical_id") |> 
  # Some events have been marked as both campaign and counterprotest/solidarity,
  # so they show up twice, but we only need one occurrence (and it doesn't
  # matter which, for this viz)
  group_by(canonical_id) |> 
  slice_head(n = 1) |> 
  group_by(geoid) |> 
  count() |> 
  ungroup() |> 
  left_join(geo, by = "geoid") |> 
  mutate(geometry = st_centroid(geometry),
         type = ifelse(geoid == "us_29019", "University of Missouri-Columbia",
                       "All other universities")) |> 
  st_as_sf(crs = st_crs(geo)) 

county_labels <- fips_codes |> 
  mutate(fips = paste0(state_code, county_code),
         name = str_wrap(paste0(county, ", ", state_name), 20)) |> 
  select(fips, name)

ggplot(mizzou_sf) +
  geom_sf(data = us_sf) +
  geom_sf(data = canada_province_shapes) +
  geom_sf(aes(size = n, shape = type), alpha = 0.5) + 
  labs(
    title = "Spread of events within the Mizzou umbrella",
  ) + 
  scale_y_continuous(limits = c(24, 50)) + 
  scale_x_continuous(limits = c(-130, -60)) + 
  labs(size = NULL, shape = NULL) + 
  theme(
    axis.text = element_blank(),
    axis.ticks = element_blank(),
  ) + 
  scale_shape_manual(
    values = c(
      "University of Missouri-Columbia" = 18,
      "All other universities" = 19
    )
  ) + 
  scale_size_continuous(breaks = seq(1, 13, by = 3), range = c(2, 8))

tibble(canonical_id = mizzou_ids) |> 
  left_join(mpeds, by = "canonical_id") |> 
  mutate(date = start_date) |> 
  group_by(date) |> 
  count() |> 
  ggplot(aes(x = date, y = n)) + 
  geom_line() + 
  geom_vline(xintercept = as.Date("2015-08-26"), color = "red") +
  annotate(geom = "text", label = "Mizzou grad student\nstrike start date",
           color = "red", x = as.Date("2015-09-12"), y = 10) + 
  scale_x_date(date_labels = "%b %y", date_breaks = "1 month") + 
  labs(
    x = "Date",
    y = "Number of canonical events starting on date",
    title = "Mizzou solidarity protest occurrences over time"
  )

```

```{r mizzou_responses}

get_mizzou_responses <- function(colname){
  n_total_with_response <- mpeds |> 
    filter(canonical_id %in% mizzou_ids,
           map_lgl({{colname}}, ~!is.null(.) &&
                     any(. != "NA/Unclear"))
           ) |> 
    nrow()
    
  name_string <- rlang::as_name(enquo(colname)) |> 
    str_replace_all("_", " ") |> 
    str_to_sentence() 
  
  mpeds |> 
    filter(canonical_id %in% mizzou_ids) |> 
    select({{colname}}) |> 
    unnest({{colname}}) |> 
    count({{colname}}) |> 
    bind_rows(tibble(
      category = "Total with valid response",
      n = n_total_with_response
    ) |> rename({{colname}} := category)) |> 
    arrange(desc(n)) |> 
    rename({{name_string}} := {{colname}},
           "Number of associated canonical events" = n) |> 
    kable()
}
# 
# get_mizzou_responses(university_discourse_on_issue)
# get_mizzou_responses(university_discourse_on_protest)
# get_mizzou_responses(university_action_on_issue)
# get_mizzou_responses(university_reactions_to_protest)
#   
```

## 2012 Quebec protest wave

```{r quebec}
# the `canonical_event_relationship` data.frame doesn't expose at first glance
# children-of-children, so we have to loop through the dataset until 
# we know we've found all of the sub-campaign events
quebec_ids <- c(2939, 2551)
new_ids <- quebec_ids
should_find_events <- TRUE
while(should_find_events){
  new_events <- tibble(canonical_id2 = new_ids) |> 
    inner_join(canonical_event_relationship, by = c("canonical_id2"))
  new_ids <- new_events$canonical_id1
  quebec_ids <- c(quebec_ids, new_ids)
  if(length(new_ids) == 0){
    should_find_events <- FALSE
  }
}

quebec_ids <- unique(quebec_ids)

quebec_events <- canonical_event_relationship |> 
  filter(canonical_id1 %in% quebec_ids | canonical_id2 %in% quebec_ids) 

quebec_by_type  <- quebec_events |> 
  mutate(relationship_type = paste0(str_to_title(relationship_type), " events only")) |> 
  count(stat = relationship_type) 
  
tribble(~stat, ~n,
        "Total number of links", nrow(quebec_events),
        "Unique events", length(unique(c(
          quebec_events$canonical_id1, quebec_events$canonical_id2
          )))) |> 
  bind_rows(quebec_by_type) |> 
  rename("Statistics for Quebec protests" = stat) |> 
  kable()

quebec_sf <- tibble(canonical_id = quebec_ids) |> 
  left_join(mpeds_sf, by = "canonical_id") |> 
  st_as_sf() |> 
  group_by(geoid) |> 
  count() |> 
  ungroup() 

top_quebec <- quebec_sf |> 
  drop_na() |> 
  arrange(desc(n)) |> 
  slice_head(n = 5) 

ggplot(quebec_sf) +
  geom_sf(data = us_sf) +
  geom_sf(data = canada_province_shapes) +
  geom_sf(aes(size = n), alpha = 0.5) + 
  labs(
    title = "Spread of Quebec solidarity events",
  ) + 
  scale_size(range = c(2, 8)) + 
  theme(
    axis.text = element_blank(),
    axis.ticks = element_blank(),
  )

tibble(canonical_id = quebec_ids) |> 
  left_join(mpeds, by = "canonical_id") |> 
  mutate(date = floor_date(start_date, "1 week")) |> 
  group_by(date) |> 
  count() |> 
  ggplot(aes(x = date, y = n)) + 
  geom_bar(stat = "identity") + 
  scale_x_date(date_labels = "%b %Y", date_breaks = "1 month") + 
  labs(
    x = "Date",
    y = "Number of canonical events starting on date",
    title = "Quebec protest occurrences over time"
  )
  
```

### Quebec events frequency stratified by police fields

For the solidarity paper, we're interested in a frequency graph of Quebec-related
protests stratified by police presence, activities, and type. It's hard to do 
this on a single graph because there are many categories involved, so instead 
I've made three separate graphs. I can also make a single image composed of 
three sub-plots for presence, activities, and type.

```{r quebec_police, warning = FALSE, message = FALSE}
police_activity_xwalk <- list(
  "Active Constraint" = c(
    "Remove Individual Protesters", 
    "Arrest or Attempted",
    "Constrain", "Arrest- Large Scale",
    "Detain", "End Protest"
  ),
  "Passive Control" = c(
    "Cooperate/Coordinate", "Monitor/Present"
  ),
  "Verbal Communication" = c(
    "Instruct/Warn", '"Breaking the Rules"', "Formal Accusation"
  ),
  "Use of Force" = c(
    "Force: Vague/Body", "Force: Weapon", "Force: 2+ Weapon Types"
  ),
  "NA/Unclear" = "NA/Unclear"
) |> 
  # im incredibly obtuse
  lmap(\(list_item){
    name <- names(list_item)
    return(tibble(umbrella = name, categories = unlist(list_item)))
  }) |> 
  reduce(bind_rows)

police_type_xwalk <- tribble(
  ~umbrella, ~categories,
  "Municipal police", "Govt police",
  "Municipal police", "Govt police - assumed",
  "Campus police", "Univ police",
  "Campus police", "Univ police - assumed",
)
  
plot_quebec_by_police <- function(colname,
                                  xwalk = tibble(umbrella = character(),
                                                 categories = character())){
  name_string <- rlang::as_name(enquo(colname))
  name_string_formatted <- name_string |> 
    str_replace_all("_", " ") |> 
    str_to_sentence() 
  
  tibble(canonical_id = quebec_ids) |> 
    left_join(mpeds, by = "canonical_id") |>
    mutate(date = floor_date(start_date, "1 week")) |> 
    select(date, categories = {{colname}}) |> 
    unnest(cols = categories) |> 
    group_by(date, categories) |> 
    count() |> 
    left_join(xwalk, by = "categories") |> 
    mutate(umbrella = ifelse(is.na(umbrella), categories, umbrella)) |> 
    ggplot(aes(x = date, y = n, fill = umbrella)) + 
    geom_bar(stat = "identity") +
    scale_x_date(date_breaks = "1 month", 
                 date_labels = "%B") +
    scale_fill_brewer(type = "qual", palette = "Set1") +
    labs(
      x = NULL,
      y = "Number of events associated with category",
      title = paste0(name_string_formatted, " during 2012 Quebec Tuition Strike"),
      fill = name_string_formatted
    )
}

plot_quebec_by_police(police_presence_and_size) 
plot_quebec_by_police(police_activities, police_activity_xwalk) 
plot_quebec_by_police(type_of_police, police_type_xwalk) +
  scale_fill_manual(values = c(
    "Campus police" = "#377EB8",
    "Municipal police" = "#E41A1C",
    "Private Security" = "#984EA3",
    '"Riot police"' = "orange"
  ))
```

Brainstorming a breakdown for activity recategorization:

- Active Constraint: Arrest or Attempted, Arrest- Large Scale, Constrain, Detain,   
  Remove Individual Protestors
- Passive Control: Cooperate/Coordinate, Monitor/Present
- Verbal Communication: Instruct/Warn, "Breaking the Rules"
- Use of Force (all force mentions)
- NA/Unclear

## Trump-related protests

Unlike the above two protest wave profiles, I'm searching for these protests based on 
issues, not by canonical event relationships.

```{r trump_events}

trump <- mpeds |> 
  filter(map_lgl(issue, ~any(. != "_Not relevant")),
         map_lgl(issue, ~any(str_detect(., "Trump")))) |> 
  mutate(date = floor_date(start_date, "1 week"),
         issue = ifelse(
           str_detect(issue, "Against"), "Anti-Trump", "Pro-Trump")
         ) 

trump |> 
  count(date, issue) |> 
  ggplot(aes(x = date, y = n, fill = issue)) + 
  geom_bar(stat = "identity") +
  annotate(geom = "text",
           x = seq.Date(
             from = as.Date("2016-05-01"), 
             to = as.Date("2018-05-01"), 
             by = "1 year"),
           y = -10,
           label = 2016:2018,
           size = 4) + 
  scale_fill_manual(values = c("Pro-Trump" = "#E41A1C", 
                               "Anti-Trump" = "#377EB8")) + 
  scale_y_continuous(breaks = seq(0, 150, by = 25)) + 
  scale_x_date(date_labels = "%b", date_breaks = "3 months") + 
  coord_cartesian(ylim = c(0, 140), expand = FALSE, clip = "off") +
  labs(
    x = NULL,
    y = "Number of events associated with given issue",
    title = "Counts of Trump-related protests over time",
    fill = NULL
  )  + 
  theme(plot.margin = unit(c(1,1,4,1), "lines"),
        axis.text = element_text(size = 12))
```

```{r trump_map}
tar_load(geo)

trump <- trump |> 
  group_by(geoid, issue) |> 
  count() |> 
  left_join(geo, by = "geoid") |> 
  mutate(geometry = st_centroid(geometry)) |> 
  st_as_sf(crs = st_crs(geo))
  
map(c("Pro-Trump", "Anti-Trump"), function(category){
  trump |> 
    filter(issue == category) |> 
    ggplot() + 
    geom_sf(data = canada_province_shapes, color = NA) + 
    geom_sf(data = us_sf) + 
    geom_sf(aes(size = n), 
            color = ifelse(category == "Pro-Trump", "#E41A1C", "#377EB8")) + 
    lims(
      x = c(-125, -65), 
      y = c(24, 50)
    ) + 
    labs(
      size = "Number of events",
      title = paste0("Geographic spread of ", category, " protests")
    ) +
    theme(text = element_text(family = "Lato"),
          axis.text = element_blank(),
          axis.ticks = element_blank(),
          plot.title = element_text(size = 20))
})
     
  
```

###  Issue composition November 9th and 17th protests

In our notes document, Dr. Berrey noted that she was surprised to see most of the
November 17th protests were non-racial, and did not have to do with sanctuary cities.
I wanted to offer some more context on that, as well as on her next comment on the
heterogeneity of Trump-related protests, so I made some tables on this point.

The day with the highest number of protests in our dataset was November 9th, 2016, holding 73 protests, 
followed by November 12th, 2015 November 16th, 2016. I've included tables for the 2016
dates showing the issue breakdown on all of these dates and also for the 
November 17th protests in case it offers any additional clarity.

It seems that "Immigration (For)", which is the issue closest to the 
topic of sanctuary cities that you thought would be at the heart of these protests,
does make a strong appearance for these days, but the general 
category of Trump-related protests still far outnumber it. Because the general Trump 
category is coded as a non-racial issue, the chart above showing racial and 
nonracial issues over time shows more nonracial issues than racial issues for November
2016.

```{r}

mpeds |> 
  count(start_date) |> 
  drop_na() |> 
  arrange(desc(n)) |> 
  head() |> 
  rename("Top dates by protest occurrence" = start_date,
         "# of events" = n) |> 
  kable()

mpeds |> 
  filter(map_lgl(racial_issue, ~("Immigration (For)" %in% .))) |> 
  count(start_date) |> 
  arrange(desc(n)) |> 
  head() |> 
  rename("Top dates for immigration-related protests" = start_date) |> 
  kable()
  
mpeds_issues <- mpeds |> 
  select(start_date, issue, racial_issue) |> 
  pivot_longer(cols = c(issue, racial_issue)) |> 
  unnest(cols = value) |> 
  filter(value != "_Not relevant") |> 
  mutate(value = ifelse(name == "racial_issue",
                        paste(value, "(racial)"), value)) |> 
  select(-name, start_date, issue = value) |> 
  group_by(start_date, issue) |> 
  count() |> 
  ungroup() |> 
  arrange(desc(n))

mpeds_issues |> 
  filter(start_date == as.Date("2016-11-09")) |> 
  select(-start_date) |> 
  rename("Top ten issues for November 9th, 2016" = issue) |> 
  slice_head(n = 10) |> 
  kable()

mpeds_issues |> 
  filter(start_date == as.Date("2016-11-16")) |> 
  select(-start_date) |> 
  rename("Top ten issues for November 16th, 2016" = issue) |> 
  slice_head(n = 10) |> 
  kable()

mpeds_issues |> 
  filter(start_date == as.Date("2016-11-17")) |> 
  select(-start_date) |> 
  rename("Top ten issues for November 17th, 2016" = issue) |> 
  slice_head(n = 10) |> 
  kable()


```

# Investigating reporting measures

- Graph of articles per event vs size of protest
  - if reporting perfect, articles should increase linearly with size of protest
  - obv will not -- what kinds of events attract lots of coverage despite being 
    

```{r}

```

