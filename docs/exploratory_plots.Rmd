---
title: "Exploratory Plots"
output: github_document
---

```{r setup, include=FALSE, message=FALSE}
library(targets)
library(knitr)
library(sf)
library(showtext)
library(tigris)
library(tidyverse)
library(GGally)

opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())

font_add_google("Lato")
showtext_auto()
```

```{r}
mpeds_raw <- tar_read(canonical_events)
mpeds_sf <- tar_read(integrated) 
mpeds <- mpeds_sf |> st_drop_geometry()
```

# Basic counts

```{r, basic_counts}
mpeds_raw_ids <- length(unique(mpeds_raw$canonical_id))
mpeds_ids <- length(unique(mpeds$canonical_id))
n_locations <- length(unique(mpeds$location))
n_fips <- length(unique(mpeds$fips))
n_universities <- length(unique(mpeds$university))

missing_unis <- mpeds$university_locations |>
  bind_rows() |>
  filter(is.na(lat), !is.na(location))
n_missing_uni_rows <- nrow(missing_unis)
n_missing_unis <- missing_unis$location |>
  unique() |> 
  length()

```

The initial import of the MPEDS db found `r mpeds_raw_ids` 
unique canonical events, and after all cleaning steps we
still have `r mpeds_ids` canonical events.

However, there's still an issue regarding duplicate matches
in IPEDS we can detect (there are likely also incorrect matches that we can't
detect programmatically right now); there are lots of schools called
"Columbia College" (or another common name) inside IPEDS, so any schools with that name
in MPEDS will be assigned multiple schools. The MPEDS-IPEDS join
is crucial because we also use IPEDS to join county FIPS identifiers,
and thus no further joins will be accurate unless the MPEDS-IPEDS
join is accurate. We currently have `r nrow(mpeds)` rows in the final
dataset, indicating that this problem applies to some
`r nrow(mpeds) - mpeds_ids` canonical events. 

Fixing it just requires a rewrite of how the join is done, so that we join on
IPEDS IDs, not names, for at least all ambiguous cases. This doesn't
require adjustments to the instructions given to student coders, but it does
require a little bit of time on my part, so it hasn't been completed yet.

Of those events, there were `r n_locations` unique locations, 
`r n_fips` unique counties, and `r n_universities` unique universities.
Surprisingly, all of the locations that were not universities 
found geocoding matches, and hand-checking the most common ones indicates that
there isn't a strong pattern of missing value substitution, e.g. Google isn't
sending the majority of results  to the centroid of America or to `(-1, -1)` or 
anything weird like that. Universities had a harder time, with `r n_missing_unis`
universities and `r n_missing_uni_rows` rows (canonical events) not returning
lon/lat coords for universities. 

That comes out to ~5% of universities not having coordinates, and
~2.5% of canonical events not having universities with coordinates.

The top universities by appearances:

```{r university_counts}

university_counts <- mpeds |> 
  group_by(university) |> 
  count() |> 
  ungroup() |> 
  drop_na() |>
  slice_max(order_by = n, n = 15)

kable(university_counts)

```
And the top locations: 


```{r location_counts}
location_counts <- mpeds |> 
  group_by(location) |> 
  count() |> 
  ungroup() |> 
  drop_na() |> 
  slice_max(order_by = n, n = 15)

kable(location_counts)
```

Top states: 

```{r state_counts}

state_fips <- fips_codes |> 
  select(state_code, state_name) |> 
  distinct()

state_counts <- mpeds |> 
  mutate(state_code = str_sub(fips, 1, 2)) |> 
  group_by(state_code) |> 
  count() |> 
  ungroup() |> 
  drop_na() |> 
  slice_max(order_by = n, n = 15) |> 
  left_join(state_fips, by = "state_code") |> 
  select(-state_code)
  
kable(state_counts)

```

And finally the top counties:

```{r county_counts}

county_fips <- fips_codes |> 
  mutate(fips = paste0(state_code, county_code),
         county_name = paste0(county, ", ", state_name)) |> 
  select(fips, county_name)

county_counts <- mpeds |> 
  group_by(fips) |> 
  count() |> 
  ungroup() |> 
  drop_na() |> 
  slice_max(order_by = n, n = 15) |> 
  left_join(county_fips, by = "fips") |> 
  select(-fips)
  
kable(county_counts)

```

These glimpses seem mostly in line with what we should expect, with a strong
caveat that the Missouri protests are not making a leading appearance here.
That's a bit alarming; some playing around with the dataset reveals there are
a fair number of protests both in Missouri and at University of Missouri-Columbia. 
There could still be errors here, so I'm continuing to revise the code.

# Basic summary plots 

```{r summary}
mpeds |> 
  select(where(function(x){is.numeric(x) || is.logical(x)}),
                 -canonical_id, -starts_with("location"),
                 -year, -uni_id, -size_category, -link) |> 
  pivot_longer(cols = everything()) |> 
  filter(name != "NA") |> 
  group_by(name) |> 
  summarize(
    type = ifelse(is.numeric(pull(mpeds[name[1]], 1)), "numeric", "boolean"),
    mean = mean(value, na.rm = TRUE),
    sd = ifelse(type == "boolean", NA_integer_, sd(value, na.rm = TRUE))
  ) |> 
  mutate(across(where(is.numeric), ~round(., 3))) |> 
  arrange(type) |> 
  kable()
```

For boolean variables, "mean" is the proportion that they are TRUE. Many of the
variables recorded in MPEDS allowed for the input of multiple values, 
so those are handled as list-cols and not shown here.

```{r pairs, warning = FALSE, width = 8, height = 8}
mpeds |> 
  select(where(is.numeric), -canonical_id, -starts_with("location"),
                 -year, -uni_id, -size_category, -enrollment_count) |> 
  ggpairs(progress = FALSE, lower = list(
    continuous = wrap(ggally_points, size = 0.1, alpha = 0.2)
    ),
    title = "Glimpse at relationships among numeric variables"
    )

```

The pairs plot is still very difficult to read after adjustments. This should be
treated as a glimpse or overview, and more detailed and cleaner plots will be made
later on.

```{r distributions}
mpeds |> 
  select(where(is.numeric), -canonical_id, -starts_with("location"),
                 -year, -uni_id, -size_category) |> 
  pivot_longer(everything()) |> 
  drop_na() |> 
  ggplot(aes(value)) + 
  geom_histogram() + 
  facet_wrap(~name, scales = "free") + 
  labs(
    title = "Glimpse of numeric covariates at the canonical event level",
    y = "Number of occurrences",
    x = "Value of variable",
  ) + 
  theme_bw() + 
  theme(text = element_text(family = "Lato"),
    strip.background = element_rect(fill = "transparent")
  )

```

# Trying out joins with protest data

To recap from our last conversation, it's a bit difficult to join the CCC data
and our data since a lot of MPEDS data points could presumably be in the CCC
records. Then CCC data could be telling us that there was a protest in the same
county, when it could just be talking about the same protest in MPEDS and
essentially be turning data quality into another covariate. 

We discussed two solutions to this problem to avoid deduplication:

- Join so that CCC protests occurring one, three, five, or seven days before the
  MPEDS protest date are matched; the CCC variable then conceptually becomes 
  "was there a recent protest in the same county." Thus protests won't find
  a match only because of duplicates
- Join only after filtering the CCC dataset so that rows with keywords related
  to universities are kicked out -- things like teachers, faculty, students,
  colleges, universities. This is less ideal than the above strategy because it
  is so nonspecific, potentially missing many university matches and kicking out
  protests related to primary and secondary schools.
  
The following chunk gives a glimpse at total number of matches:

```{r external_protest_sources}
ccc <- tar_read(ccc) |> 
  distinct() |> 
  rename(protest_date = ccc_protest_date)

blm <- tar_read(elephrame_blm) |> 
  distinct() |> 
  rename(protest_date = blm_protest_date)
  
# We want to assess successful match rates in a sensible manner, which means 
# restricting the MPEDS dataset to just the protest years available in either 
# CCC or Elephrame
n_ccc <- matched_mpeds |> 
  filter(start_date > min(ccc$protest_date, na.rm = TRUE)) |> 
  nrow()
n_elephrame <- matched_mpeds |> 
  filter(start_date > min(blm$protest_date, na.rm = TRUE)) |> 
  nrow()

test_date_diffs <- function(protests){
  # a version where dates are a list-col, to assist in the testing below
  protest_dates <- protests |> 
    group_by(fips) |> 
    summarize(recent_protest_dates_lst = list(protest_date))
  matched_mpeds <- mpeds |> 
    left_join(protest_dates, by = "fips") 
  
  # return a TRUE value if any protests in `vec` occurred between 
  # a given date and `diff` days after that date
  compute_protests <- function(vec, date, diff){
    if(is.na(date)) return(NA)
    any(vec %in% (date + 1):(diff + date))
  }
  
  match_date_diff <- function(diff){
    # For each canonical event, use the `recent_protest_dates_lst` column
    # representing protests in the same county to assess if any
    # those nearby protests happened recently
    recent_protests <- matched_mpeds |> 
      mutate(
        has_recent_protest_nearby = unlist(map2(
          recent_protest_dates_lst, start_date,
          function(x,y){compute_protests(x, y, diff)}
        ))
      )
    
    n_matches <- sum(recent_protests$has_recent_protest_nearby, na.rm = TRUE)
    
    tribble(~date_offset, ~recent_protests,
            diff, n_matches, 
            )
    
  }
  return(map_dfr(c(0,1,3,5,7), match_date_diff))
}

match_results <- map_dfr(list("CCC" = ccc, "Elephrame" = blm),
                         test_date_diffs, .id = "source") |> 
  mutate(match_percentage = ifelse(
    source == "CCC", 100 * recent_protests / n_ccc,
    100 * recent_protests / n_elephrame
  ))

kable(match_results)

```

Here, the `match_percentage` column indicates how many canonical events saw another
protest occur in the same county within `diff` days, according to the dataset
in `source`. The fact that the match rate for 0 is much higher than 1 for both
Elephrame and CCC indicates that there is some double-counting of protests;
rather than multiple protests occurring concurrently, we may have recorded a protest
in our dataset that is also present in another dataset.

So it seems that there are a fair number of duplicates occurring if we don't
have a date offset, but once we add one (of any days) that pretty much solves
the data quality issue.

That being said, the likely larger problem with the CCC data is that it's only 
available after 2017, so it may not be relevant even after we become satisfied
with the deduped match process. This can be refined a little bit by adding in 
Elephrame data on BLM protests, but we've had problems there already, and the topic 
differences mean we can't pretend we have complete data.

# Maps and related things

```{r maps, message = FALSE, warning = FALSE}
county_sf <- counties(keep_zipped_shapefile = TRUE, progress_bar = FALSE) |> 
  select(fips = GEOID)
us_sf <- states(progress_bar = FALSE) |> 
  filter(!(NAME %in% c("Hawaii", "Puerto Rico", "American Samoa", 
                       "United States Virgin Islands", 
                       "Commonwealth of the Northern Mariana Islands",
                       "Alaska", "Guam"))) |> 
  st_union()
```

```{r mpeds_map}

mpeds_sf |> 
  st_transform(st_crs(county_sf)) |>
  mutate(geometry = st_jitter(geometry, factor = 0.005)) |> 
  ggplot() + 
  geom_sf(data = us_sf, fill = "white", color = "gray") + 
  geom_sf(size = 0.1, alpha = 0.2) + 
  lims(
    x = c(-130, -60),
    y = c(20, 55)
  ) +
  labs(
    title = "Spread of canonical events and geocoded locations",
    subtitle = "Locations jittered slightly, by 0.005*bounding box diagonal.",
    caption = "Alaska, Hawaii, a few other locations with only a\nfew protests excluded in this map only."
  ) + 
  theme_void() + 
  theme(text = element_text(family = "Lato"),
        plot.title = element_text(size = 20))
  

```

