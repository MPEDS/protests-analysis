---
title: "Exploratory Plots"
output: github_document
---

```{r setup, include=FALSE, message=FALSE}
library(targets)
library(knitr)
library(sf)
library(showtext)
library(tigris)
library(tidyverse)
library(GGally)
library(RColorBrewer)
library(gridExtra)
library(cowplot)

opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
opts_chunk$set(echo = FALSE, warning = FALSE, fig.width = 10, fig.height = 7)

font_add_google("Lato")
showtext_auto()

custom_theme <- function(...){
  theme_bw() + 
    theme(
      text = element_text(family = "Lato", size = 14),
      ...
    )
}

theme_set(custom_theme())
```

```{r}
# During interactive use, this chunk has to be loaded separately from the setup chunk.
# `targets` looks for a `_targets/` directory but cannot find one
# if the working directory is pointed at the `docs/` directory already, as is the
# case with Rmarkdown documents by default.

# The line starting with `opts_knit$set` above sets the correct working directory,
# but it only applies for chunks after the setup chunk, hence the separation of 
# the data load and the rest of the setup

# This is quite annoying workflow-wise, as the setup chunk is loaded automatically
# but this chunk isn't
mpeds_raw <- tar_read(canonical_events)
mpeds_sf <- tar_read(integrated) 
mpeds <- mpeds_sf |> st_drop_geometry()
```

# Basic counts

```{r, basic_counts}
mpeds_raw_ids <- length(unique(mpeds_raw$canonical_id))
mpeds_ids <- length(unique(mpeds$canonical_id))
n_locations <- length(unique(mpeds$location))
n_counties <- mpeds |> 
  filter(str_detect(geoid, "^us_")) |> 
  pull(geoid) |> 
  unique() |> 
  length()
n_cmas <- mpeds |> 
  filter(str_detect(geoid, "^canada_")) |> 
  pull(geoid) |> 
  unique() |> 
  length()
n_universities <- length(unique(mpeds$university))

missing_unis <- mpeds$university_locations |>
  bind_rows() |>
  filter(is.na(lat), !is.na(location))
n_missing_uni_rows <- nrow(missing_unis)
n_missing_unis <- missing_unis$location |>
  unique() |> 
  length()

n_has_police <- mpeds |> 
  filter(!map_lgl(police_presence_and_size, is.null),
         !map_lgl(police_presence_and_size, ~all(. == "NA/Unclear"))
         ) |> 
  nrow()

n_has_police_activity <- mpeds |> 
  filter(!map_lgl(police_activities, is.null),
         !map_lgl(police_activities, ~all(. == "NA/Unclear"))
         ) |> 
  nrow()

police_only <- mpeds |> 
  filter(if_any(c(
    police_presence_and_size,
    police_activities,
    police_actions,
    type_of_police
  ), ~!map_lgl(.,\(x){is.null(x)}))) |>
  filter(if_any(c(
    police_presence_and_size, 
    police_activities,
    police_actions,
    type_of_police
  ), ~map_lgl(., \(x){any(x != "NA/Unclear")}))) 

n_any_police_field <- police_only |> 
  nrow()

n_both_pa_ur <- police_only |> 
  filter(if_any(c(
    university_action_on_issue,
    university_responses,
    university_reactions_to_protest,
    university_discourse_on_protest,
    university_discourse_on_issue
  ), ~!map_lgl(., function(x){
    is.null(x)
  }))) |> filter(if_any(c(
    university_action_on_issue,
    university_responses,
    university_reactions_to_protest,
    university_discourse_on_protest,
    university_discourse_on_issue
  ), ~map_lgl(., \(x){any(x != "NA/Unclear")}))) |> 
  nrow()

# only PA (any PA field)
# only UR (any UR field)
# no response (no recorded PA or UR field)

n_uni_police_only <- mpeds |> 
  filter(!map_lgl(type_of_police, is.null),
         map_lgl(type_of_police, function(x){
    all(x %in% c("Univ police", "Univ police - assumed"))
  })) |> 
  nrow()

n_govt_police_only <- mpeds |> 
  filter(!map_lgl(type_of_police, is.null),
         map_lgl(type_of_police, function(x){
    all(x %in% c("Govt police", "Govt police - assumed", '"Riot police"'))
  })) |> 
  nrow()

n_uni_and_govt_police <- mpeds |> 
  filter(!map_lgl(type_of_police, is.null),
         map_lgl(type_of_police, function(x){
    any(x %in% c("Univ police", "Univ police - assumed"))
         }),
         map_lgl(type_of_police, function(x){
    any(x %in% c("Govt police", "Govt police - assumed", '"Riot police"'))
         })
    ) |> 
  nrow()

  
  

tribble(
  ~Statistic, ~Value,
  "Total imported events", mpeds_raw_ids,
  "Total events after cleaning", mpeds_ids,
  "Unique locations", n_locations,
  "US counties", n_counties,
  "Canadian CMAs", n_cmas,
  "Universities", n_universities,
  "Missing universities", n_missing_unis,
  "CEs with missing universities", n_missing_uni_rows,
  "# of events with police activity recorded", n_has_police_activity,
  "# of events with any police field recorded", n_any_police_field,
  "# of events with university police only", n_uni_police_only,
  "# of events with government police only", n_govt_police_only,
  "# of events with both types of police", n_uni_and_govt_police 
) |> 
  kable()


```

The initial import of the MPEDS db found `r mpeds_raw_ids` 
unique canonical events, and after all cleaning steps we
still have `r mpeds_ids` canonical events.

However, there's still an issue regarding duplicate matches
in IPEDS we can detect (there are likely also incorrect matches that we can't
detect programmatically right now); there are lots of schools called
"Columbia College" (or another common name) inside IPEDS, so any schools with that name
in MPEDS will be assigned multiple schools. The MPEDS-IPEDS join
is crucial because we also use IPEDS to join county FIPS identifiers,
and thus no further joins will be accurate unless the MPEDS-IPEDS
join is accurate. As of Jan 30, 2023, we are in the middle of repairing
this join. 

Of those events, there were `r n_locations` unique locations, 
`r n_counties` unique counties, `r n_cmas` unique Canadian CMAs, and `r n_universities` unique universities.
Surprisingly, all of the locations that were not universities 
found geocoding matches, and hand-checking the most common ones indicates that
there isn't a strong pattern of missing value substitution, e.g. Google isn't
sending the majority of results  to the centroid of America or to `(-1, -1)` or 
anything weird like that. Universities had a harder time, with `r n_missing_unis`
universities and `r n_missing_uni_rows` rows (canonical events) not returning
lon/lat coords for universities. 

That comes out to ~5% of universities not having coordinates, and
~2.5% of canonical events not having universities with coordinates.

The top universities by appearances:

```{r university_counts}

university_counts <- mpeds |> 
  group_by(university) |> 
  count() |> 
  ungroup() |> 
  drop_na() |>
  slice_max(order_by = n, n = 15)

kable(university_counts)

```
And the top locations: 


```{r location_counts}
location_counts <- mpeds |> 
  group_by(location) |> 
  count() |> 
  ungroup() |> 
  drop_na() |> 
  slice_max(order_by = n, n = 15)

kable(location_counts)
```

Top states: 

```{r state_counts}


state_counts <- mpeds |> 
  group_by(area_name) |> 
  count() |> 
  ungroup() |> 
  drop_na() |> 
  slice_max(order_by = n, n = 15) 
  
kable(state_counts)

```

And finally the top counties:

```{r county_counts}

county_fips <- fips_codes |> 
  mutate(fips = paste0(state_code, county_code),
         county_name = paste0(county, ", ", state_name)) |> 
  select(fips, county_name)

county_counts <- mpeds |> 
  group_by(locality_name) |> 
  count() |> 
  ungroup() |> 
  drop_na() |> 
  slice_max(order_by = n, n = 15) 
  
kable(county_counts)

```

These glimpses seem mostly in line with what we should expect, with a strong
caveat that the Missouri protests are not making a leading appearance in the 
counts by location, but there do seem to be a fair number in Missouri when we
take a look by state. It seems there are non-MO locations being recognized as
happening in Missouri. See our 1:1 notes Google Doc for details.

```{r police_counts}
# God that was hard
glimpse_counts <- function(colname){
  mpeds |>
    mutate("{{ colname }}" := map({{ colname }}, \(item){
      if(is.null(item)){
        return(NA)
      }
      return(str_replace_all(item, "\n", " "))
      })) |>
    select({{colname}}) |> 
    unnest(cols = {{colname}}) |> 
    group_by({{ colname }}) |> 
    count({{ colname }}) |> 
    arrange(desc(n)) |> 
    kable()
}

glimpse_counts(police_presence_and_size)
glimpse_counts(police_activities)
glimpse_counts(type_of_police)
```

```{r university_responses_counts}
glimpse_counts(university_action_on_issue)
glimpse_counts(university_discourse_on_issue)
glimpse_counts(university_reactions_to_protest)
```

"NA" marks canonical events where issues were not assigned at all, or where
text-selects were used but not one of the preset issue categories. "_Not relevant"
*should* be marked when a racial issue was selected instead, per the codebook.
"_Other issue" marks issues not within the preset options; the codebook gives the
examples of:

- protestors who use hateful speech, e.g. anti-LGBTQ preachers
- (objection to?) corporate practices
- access to higher education (?)
- science (?)
- Armenian genocide (?)

Hm. 

## Counts by issue

```{r}
glimpse_counts(issue)
```

## Counts by racial issue:

```{r}
glimpse_counts(racial_issue)
```

# Percentages of all protest with given preset

```{r}
get_percent <- function(colname){
  n_total <- length(unique(mpeds$canonical_id))
  pct_any <- mpeds |> 
    filter(!({{colname}} %in% c("_Not relevant", "")),
           map_lgl({{colname}}, ~!is.null(.)))
  mpeds |>
    mutate("{{ colname }}" := map({{ colname }}, \(item){
      if(is.null(item)){
        return(NA)
      }
      return(str_replace_all(item, "\n", " "))
      })) |>
    select({{colname}}) |> 
    unnest(cols = {{colname}}) |> 
    group_by({{ colname }}) |> 
    count({{ colname }}) |> 
    mutate(pct = round(100 * n / n_total, 2)) |> 
    select(-n) |> 
    bind_rows(tibble({{colname}} := "Percent of events with any value",
                     pct = round(100 * nrow(pct_any) / n_total, 2))) |> 
    arrange(desc(pct)) |> 
    kable()
}

get_percent(issue)
get_percent(racial_issue)
```

# Counts over time

```{r basic_counts_over_time}

mpeds |> 
  mutate(date = floor_date(start_date, "month")) |> 
  group_by(date) |> 
  count() |> 
  drop_na() |> 
  ggplot(aes(x = date, y = n)) + 
  geom_line() +
  scale_x_date(breaks = "4 months",
               date_labels =  "%b",
               sec.axis = dup_axis(
                 breaks = seq(as.Date("2012-01-01"), as.Date("2018-01-01"), by = "year"),
                 labels = scales::label_date("%Y"),
               )
               ) + 
  labs(
    title = "Basic counts of canonical events over time",
    x = "Date (floored to months)",
    y = "Number of associated canonical events"
  ) 
```

```{r basic_counts_time_redux, fig.height = 10, fig.width = 7}

plots <- map(2012:2018, function(yr){
  mpeds |> 
    mutate(date = floor_date(start_date, "month")) |> 
    filter(lubridate::year(date) == yr) |> 
    group_by(date) |> 
    count() |> 
    drop_na() |> 
    ggplot(aes(x = date, y = n)) + 
    geom_line() + 
    labs(y = NULL, x = NULL, title = yr) + 
    scale_y_continuous(limits = c(0, 400)) +
    scale_x_date(date_labels = "%b", date_breaks = "2 months") + 
    theme(
      plot.title = element_text(size = 11),
      axis.text.x = if(yr == 2018){element_text()}else {element_blank()}
      )
})
title_grob <- ggdraw() + 
  draw_label("Counts of canonical events over time",
             x = 0.05, 
             hjust = 0, 
             fontfamily = "Lato",
             fontface = "bold"
            ) +
  theme(plot.margin = unit(c(0, 0, 0, 0), "cm"))
plot_grid(title_grob, plotlist = plots, ncol = 1)

```


```{r regions_over_time}
protests_by_region <- mpeds |> 
  mutate(region = case_when(
    str_detect(geoid, "^canada_") ~ paste(region_name, "(CA)"),
    is.na(region_name) ~ NA_character_,
    TRUE ~ region_name)
    ) |> 
  mutate(date = floor_date(start_date, "month"),
         region = as_factor(region) |> 
           fct_reorder(ifelse(!str_detect(geoid, "^canada_"), 0, 1))) |> 
  group_by(region, date) |> 
  count() |> 
  drop_na() 

protests_region_plot <- ggplot(protests_by_region,
       aes(fill = region, x = date, y = n)) + 
  geom_bar(stat = "identity") + 
  scale_x_date(breaks = "4 months",
               date_labels =  "%b",
               sec.axis = dup_axis(
                 breaks = seq(as.Date("2012-01-01"), as.Date("2018-01-01"), by = "year"),
                 labels = scales::label_date("%Y"),
               )
               ) + 
  scale_fill_brewer(type = "qual", palette = "Set1") + 
  labs(
    title = "Events over time by region",
    x = "Date (floored to months)",
    y = "Number of associated canonical events", 
    color = "U.S. Census region,\nor Canadian province"
  ) 

protests_region_plot

```

```{r regions_time_vert, fig.height = 10, fig.width = 8}

plots <- map(2012:2018, function(yr){
  protests_by_region |> 
    filter(lubridate::year(date) == yr) |> 
    ggplot(aes(fill = region, x = date, y = n)) + 
    geom_bar(stat = "identity") + 
    labs(y = NULL, x = NULL, title = yr) + 
    # scale_y_continuous(limits = c(0, 400)) +
    scale_x_date(date_labels = "%b", date_breaks = "2 months") + 
    scale_fill_brewer(type = "qual", palette = "Set1") + 
    theme(
      legend.position = "none",
      plot.title = element_text(size = 11),
      axis.text.x = if(yr == 2018){element_text()}else {element_blank()}
      )
})

get_legend<-function(gg){
  tmp <- ggplot_gtable(ggplot_build(gg))
  leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
  legend <- tmp$grobs[[leg]]
  return(legend)
}

legend_grob <- get_legend(protests_region_plot +
                            labs(fill = NULL) + 
                            theme(legend.position = "bottom")
                          )

title_grob <- ggdraw() + 
  draw_label("Counts of canonical events over time by region",
             x = 0.05, 
             hjust = 0, 
             fontfamily = "Lato",
             fontface = "bold"
            ) +
  theme(plot.margin = unit(c(0, 0, 0, 0), "cm"))

plot_grid(title_grob, plotlist = plots, legend_grob, ncol = 1)

```

```{r over_time_country}

protests_by_country <- mpeds |> 
  mutate(
    country = ifelse(
      str_detect(geoid, "us_"), "United States", "Canada"
    )
    ) |> 
  mutate(date = floor_date(start_date, "month")) |> 
  group_by(country, date) |> 
  count() |> 
  drop_na() 

ggplot(protests_by_country, aes(fill = country, x = date, y = n)) + 
  geom_bar(stat = "identity") + 
  scale_fill_brewer(type = "qual", palette = "Set1") + 
  scale_x_date(date_breaks = "6 months",
               date_labels = "%b %y",
               guide = guide_axis(n.dodge = 2)) + 
  labs(
    y = "Number of associated canonical events",
    x = "Date (floored to months)",
    fill = "Country",
    title = "Canonical events by country"
  ) 
```

We can also begin to look at the top universities, counties, locations, or states
over time. This inevitably produces more complex summaries, and it can
be difficult to take an informative glimpse given so many categories, so I've only
shown the universities over time for now:

```{r unis_over_time}
uni_grouping <- tribble(
  ~university, ~group,
  "Columbia University in the City of New York", "Northeast",
  "Harvard University", "Northeast",
  "Tufts University", "Northeast",
  "Concordia University",  "Quebec",
  "McGill University", "Quebec",
  "University of Toronto", "Ontario",
  "Ryerson University", "Ontario",
  "University of California-Berkeley", "California",
  "University of California-Los Angeles", "California",
  "University of Chicago", "Midwest",
  "University of Michigan-Ann Arbor", "Midwest",
  "University of Wisconsin-Madison", "Midwest"
)

unis_over_time <- mpeds |> 
  mutate(date = floor_date(start_date, "month")) |> 
  group_by(university, date) |> 
  count() |> 
  drop_na() |> 
  filter(university %in% university_counts$university[1:10]) |> 
  mutate(university = str_wrap(university, 15)) |> 
  left_join(uni_grouping, by = "university")

uni_plot <- ggplot(unis_over_time, aes(x = date, y = n, fill = university)) + 
  geom_bar(stat = "identity") + 
  scale_fill_brewer(type = "qual", palette = "Paired") + 
  labs(
    x = paste0("Time (months)"),
    y = "Number of associated canonical events",
    title = "Top universities by protest count over time",
    caption = paste("Universities displayed are top 10 overall universities
    by protest count, not a top university in a given year.", 
    "Dates are aggregated to the month unit.")
  ) + 
  guides(fill = guide_legend(byrow = TRUE)) + 
  theme(legend.spacing.y = unit(0.2, "cm")) + 
  scale_x_date(breaks = "4 months",
               date_labels =  "%b",
               sec.axis = dup_axis(
                 breaks = seq(as.Date("2012-01-01"), as.Date("2018-01-01"), by = "year"),
                 labels = scales::label_date("%Y"),
               )
               )
  
uni_plot

uni_grouping_over_time <- mpeds |> 
  mutate(date = floor_date(start_date, "month")) |> 
  filter(university %in% university_counts$university[1:10]) |> 
  left_join(uni_grouping, by = "university") |> 
  group_by(group, date) |> 
  count() |> 
  drop_na() 

uni_grouped_plot <- ggplot(uni_grouping_over_time, aes(x = date, y = n, fill = group)) + 
  geom_bar(stat = "identity") + 
  scale_fill_brewer(type = "qual", palette = "Set1") + 
  scale_x_date(breaks = "4 months",
               date_labels =  "%b",
               sec.axis = dup_axis(
                 breaks = seq(as.Date("2012-01-01"), as.Date("2018-01-01"), by = "year"),
                 labels = scales::label_date("%Y"),
               )
               ) + 
  labs(
    x = paste0("Time (floored to months)"),
    y = "Number of associated canonical events",
    title = "Top university groups by protest count over time",
    caption = paste("Dates are aggregated to the month unit.")
  ) 

uni_grouped_plot
```


```{r responses_over_time}
plot_response_over_time <- function(colname){
  unnested <- mpeds |>
    mutate("{{ colname }}" := map({{ colname }}, \(item){
      if(is.null(item)){
        return(NA)
      }
      return(item)
      })) |>
    select(start_date, {{colname}}) |> 
    unnest(cols = {{colname}}) |> 
    filter(!is.na({{colname}}), {{colname}} != "NA/Unclear")
  
  top_overall <- unnested |> 
    count({{colname}}) |> 
    arrange(desc(n)) |> 
    slice(1:9) |> 
    pull({{colname}}) 
  
  name_string <- rlang::as_name(enquo(colname)) |> 
    str_replace_all("_", " ") |> 
    str_to_sentence() 
  
  unnested |> 
    filter({{colname}} %in% top_overall) |> 
    mutate(date = floor_date(start_date, "month")) |> 
    group_by({{colname}}, date) |> 
    count() |> 
    ggplot(aes(x = date, y = n, fill = {{colname}})) + 
    geom_bar(stat = "identity") + 
    scale_fill_brewer(type = "qual", palette = "Paired") + scale_x_date(breaks = "4 months",
               date_labels =  "%b",
               sec.axis = dup_axis(
                 breaks = seq(as.Date("2012-01-01"), as.Date("2018-01-01"), by = "year"),
                 labels = scales::label_date("%Y"),
               )
               ) + 
    scale_x_date(breaks = "4 months",
               date_labels =  "%b",
               sec.axis = dup_axis(
                 breaks = seq(as.Date("2012-01-01"), as.Date("2018-01-01"), by = "year"),
                 labels = scales::label_date("%Y"),
               )
               ) + 
    labs(
      title = paste(name_string, "over time"),
      y = "Number of occurrences",
      x = "Date (month)",
      fill = name_string
    ) +
    guides(fill = guide_legend(byrow = TRUE)) +
    theme(
      legend.spacing.y = unit(0.2, "cm")
    )
}

plot_response_over_time(police_presence_and_size)
plot_response_over_time(police_activities)
plot_response_over_time(type_of_police)
plot_response_over_time(university_action_on_issue)
plot_response_over_time(university_discourse_on_issue)
plot_response_over_time(university_reactions_to_protest)
```

```{r issues_over_time}
# Tad tricky since there are often multiple issues per role
issues <- mpeds |> 
  select(issue, start_date) |> 
  unnest(cols = issue) |> 
  mutate(date = floor_date(start_date, "month"),
         issue = str_wrap(issue, 20),
         ) |> 
  filter(issue != "_Not relevant")

racial_issue <- mpeds |> 
  select(issue = racial_issue, start_date) |> 
  unnest(cols = issue) |> 
  mutate(date = floor_date(start_date, "month"),
         issue = str_wrap(issue, 20),
         ) |> 
  filter(issue != "_Not relevant")

# 42 rows is still readable so I'll just print the entire table
issues_count <- issues |> 
  count(issue) |> 
  arrange(desc(n)) 

racial_issue_count <- racial_issue |> 
  count(racial_issue = issue) |> 
  arrange(desc(n))

racial_issue_count |> 
  mutate(racial_issue = str_replace_all(racial_issue, "\n", ' ')) |> 
  kable()

top_racial_issues <- racial_issue |> 
  filter(issue %in% racial_issue_count$racial_issue[1:4]) |> 
  mutate(issue = paste(issue, "(racial)"))


# 42 lines on a plot on the other hand is like 35 too many
issues |> 
  filter(issue %in% issues_count$issue[1:7]) |> 
  group_by(issue, date) |> 
  count() |> 
  drop_na() |> 
  ggplot(aes(x = date, y = n, fill = issue)) + 
  geom_bar(stat = "identity") + 
  scale_fill_brewer(type = "qual", palette = "Set1") + 
  scale_x_date(breaks = "4 months",
             date_labels =  "%b",
             sec.axis = dup_axis(
               breaks = seq(as.Date("2012-01-01"), as.Date("2018-01-01"), by = "year"),
               labels = scales::label_date("%Y"),
             )
             ) + 
  labs(
    title = "Issue breakdown over time",
    y = "Number of associated canonical events",
    x = "Date (month)",
    caption = "Excludes racial issues."
  ) +
  guides(fill = guide_legend(byrow = TRUE)) +
  theme(
    legend.spacing.y = unit(0.5, "cm")
  )
  
issues |>
  filter(issue %in% issues_count$issue[1:4]) |> 
  bind_rows(top_racial_issues) |> 
  mutate(issue = as.factor(issue) |> 
           fct_relevel(c(
             issues_count$issue[1:4],
             racial_issue_count$racial_issue[1:4])
             )) |> 
  group_by(issue, date) |> 
  count() |> 
  drop_na() |> 
  ggplot(aes(x = date, y = n, fill = issue)) + 
  geom_bar(stat = "identity") + 
  scale_fill_brewer(type = "qual", palette = "Set1") + 
  labs(
    title = "Issue breakdown over time",
    y = "Number of associated canonical events",
    x = "Date (month)",
    caption = "Includes racial issues."
  ) +
  guides(fill = guide_legend(byrow = TRUE)) +
  theme(
    legend.spacing.y = unit(0.5, "cm")
  )
  

# one where y-axis percentage of total issues in given month
# We want to divide the number of CEs associated with an issue in a month
# by the total number of CEs in a month; that latter statistic we have to get by 
# using `mutate` instead of `summarize` in order to preserve the tibble format, 
# but that means that the resulting column of counts will be duplicated,
# as in we'll have one count of total issues for each issue occurrence in a month
# I use `n_events1]` to resolve that
issues |> 
  group_by(date) |> 
  mutate(
    n_events = n()
  ) |> 
  group_by(issue, date)  |> 
  summarize(
    issue_pct = n() / n_events[1],
    .groups = "drop"
  ) |> 
  filter(issue %in% issues_count$issue[1:7]) |> 
  mutate(issue = fct_relevel(issue, issues_count$issue[1:7])) |> 
  ggplot(aes(x = date, y = issue_pct, fill = issue)) + 
  geom_bar(stat = "identity") + 
  scale_fill_brewer(type = "qual", palette = "Set1") + 
  labs(
    title = "Most common issues over time",
    caption = "Bars don't add up to 1.00 because I selected the top issues for display.
    42 issues in total is difficult to present."
  )
```

## Racial and "nonracial" issues over time (collapsed)

```{r}

# Separate cases required because of the way R checks for types and length
has_issue <- function(list_item){
  if(length(list_item) == 1){
    return(list_item != "_Not relevant") 
  } else {
    return(TRUE)
  }
}

# Assembling issues and racial issues into one plot
mpeds |> 
  filter(!map_lgl(racial_issue, is.null),
         !map_lgl(issue, is.null)) |> 
  mutate(`Racial issue` = map_lgl(racial_issue, has_issue),
         `Nonracial issue` = map_lgl(issue, has_issue),
         date = floor_date(start_date, "1 month"))  |> 
  select(`Nonracial issue`, `Racial issue`, date) |> 
  pivot_longer(cols = c(`Nonracial issue`, `Racial issue`),
               names_to = "type") |> 
  mutate(type = fct_relevel(
    type, "Racial issue", "Nonracial issue"
    )) |> 
  filter(value) |>
  group_by(date, type) |> 
  count() |> 
  ggplot(aes(x = date, y = n, fill = type)) + 
  geom_bar(stat = "identity") +
  labs(
    y = "Number of associated canonical events",
    x = "Date (floored to months)",
    title = "Racial and `non-racial` issues over time"
  ) + 
  scale_fill_brewer(type = "qual", palette = "Set1") 

mpeds |> 
  filter(!map_lgl(racial_issue, is.null),
         !map_lgl(issue, is.null)) |> 
  mutate(`Racial issue` = map_lgl(racial_issue, has_issue),
         `Nonracial issue` = map_lgl(issue, has_issue),
         date = floor_date(start_date, "1 month"))  |> 
  select(`Nonracial issue`, `Racial issue`, date) |> 
  pivot_longer(cols = c(`Nonracial issue`, `Racial issue`),
               names_to = "type") |> 
  mutate(type = fct_relevel(
    type, "Racial issue", "Nonracial issue"
    )) |> 
  filter(value) |>
  filter(value) |>
  group_by(date, type) |> 
  count() |> 
  group_by(date) |> 
  mutate(pct = n / sum(n)) |> 
  ggplot(aes(x = date, y = pct, fill = type)) + 
  geom_bar(stat = "identity") +
  labs(
    y = "Share of canonical events during given month",
    x = "Date (floored to months)",
    title = "Proportion of racial and `non-racial` issues over time"
  ) +
  scale_fill_brewer(type = "qual", palette = "Set1") 
  
```

groI've collapsed both types of issues here to show racial and nonracial issues 
alongside each other. Racial issue counts here are taken at a maximum of one per 
canonical event, so that events that relate to many issues do not outweight others
and we have a clearer understanding of the weight of protest occurrence.
The same goes for nonracial issues. However, this does mean that if a protest
has both nonracial and racial issues, it will be counted twice in this chart.


# Basic summary plots by variable

```{r summary}
mpeds |> 
  select(where(function(x){is.numeric(x) || is.logical(x)}),
                 -canonical_id, -starts_with("location"),
                 -year, -uni_id, -size_category, -link) |> 
  pivot_longer(cols = everything()) |> 
  filter(name != "NA") |> 
  group_by(name) |> 
  summarize(
    type = ifelse(is.numeric(pull(mpeds[name[1]], 1)), "numeric", "boolean"),
    mean = mean(value, na.rm = TRUE),
    sd = ifelse(type == "boolean", NA_integer_, sd(value, na.rm = TRUE))
  ) |> 
  mutate(across(where(is.numeric), ~round(., 3))) |> 
  arrange(type) |> 
  kable()
```

For boolean variables, "mean" is the proportion that they are TRUE. Many of the
variables recorded in MPEDS allowed for the input of multiple values, 
so those are handled as list-cols and not shown here.

```{r pairs, warning = FALSE, width = 8, height = 8}
mpeds |> 
  select(where(is.numeric), -canonical_id, -starts_with("location"),
                 -year, -uni_id, -size_category, -enrollment_count) |> 
  ggpairs(progress = FALSE, lower = list(
    continuous = wrap(ggally_points, size = 0.1, alpha = 0.2)
    ),
    title = "Glimpse at relationships among numeric variables"
    )

```

The pairs plot is still very difficult to read after adjustments. This should be
treated as a glimpse or overview, and more detailed and cleaner plots will be made
later on.

```{r distributions}
mpeds |> 
  select(where(is.numeric), -canonical_id, -starts_with("location"),
                 -year, -uni_id, -size_category) |> 
  pivot_longer(everything()) |> 
  drop_na() |> 
  ggplot(aes(value)) + 
  geom_histogram() + 
  facet_wrap(~name, scales = "free") + 
  labs(
    title = "Glimpse of numeric covariates at the canonical event level",
    y = "Number of occurrences",
    x = "Value of variable",
  )

```

# Trying out joins with protest data

To recap from our last conversation, it's a bit difficult to join the CCC data
and our data since a lot of MPEDS data points could presumably be in the CCC
records. Then CCC data could be telling us that there was a protest in the same
county, when it could just be talking about the same protest in MPEDS and
essentially be turning data quality into another covariate. 

We discussed two solutions to this problem to avoid deduplication:

- Join so that CCC protests occurring one, three, five, or seven days before the
  MPEDS protest date are matched; the CCC variable then conceptually becomes 
  "was there a recent protest in the same county." Thus protests won't find
  a match only because of duplicates
- Join only after filtering the CCC dataset so that rows with keywords related
  to universities are kicked out -- things like teachers, faculty, students,
  colleges, universities. This is less ideal than the above strategy because it
  is so nonspecific, potentially missing many university matches and kicking out
  protests related to primary and secondary schools.
  
The following chunk gives a glimpse at total number of matches:

```{r external_protest_sources}
ccc <- tar_read(ccc) |> 
  distinct() |> 
  rename(protest_date = ccc_protest_date)

blm <- tar_read(elephrame_blm) |> 
  distinct() |> 
  rename(protest_date = blm_protest_date)
  
# We want to assess successful match rates in a sensible manner, which means 
# restricting the MPEDS dataset to just the protest years available in either 
# CCC or Elephrame
n_ccc <- mpeds |> 
  filter(start_date > min(ccc$protest_date, na.rm = TRUE)) |> 
  nrow()
n_elephrame <- mpeds |> 
  filter(start_date > min(blm$protest_date, na.rm = TRUE)) |> 
  nrow()

test_date_diffs <- function(protests){
  # a version where dates are a list-col, to assist in the testing below
  protest_dates <- protests |> 
    group_by(fips) |> 
    summarize(recent_protest_dates_lst = list(protest_date))
  matched_mpeds <- mpeds |> 
    left_join(protest_dates, by = c("geoid" = "fips"))
  
  # return a TRUE value if any protests in `vec` occurred between 
  # a given date and `diff` days after that date
  compute_protests <- function(vec, date, diff){
    if(is.na(date)) return(NA)
    any(vec %in% (date + 1):(diff + date))
  }
  
  match_date_diff <- function(diff){
    # For each canonical event, use the `recent_protest_dates_lst` column
    # representing protests in the same county to assess if any
    # those nearby protests happened recently
    recent_protests <- matched_mpeds |> 
      mutate(
        has_recent_protest_nearby = unlist(map2(
          recent_protest_dates_lst, start_date,
          function(x,y){compute_protests(x, y, diff)}
        ))
      )
    
    n_matches <- sum(recent_protests$has_recent_protest_nearby, na.rm = TRUE)
    
    tribble(~date_offset, ~recent_protests,
            diff, n_matches, 
            )
    
  }
  return(map_dfr(c(0,1,3,5,7), match_date_diff))
}

match_results <- map_dfr(list("CCC" = ccc, "Elephrame" = blm),
                         test_date_diffs, .id = "source") |> 
  mutate(match_percentage = ifelse(
    source == "CCC", 100 * recent_protests / n_ccc,
    100 * recent_protests / n_elephrame
  ))

kable(match_results)

```

Here, the `match_percentage` column indicates how many canonical events saw another
protest occur in the same county within `diff` days, according to the dataset
in `source`. The fact that the match rate for 0 is much higher than 1 for both
Elephrame and CCC indicates that there is some double-counting of protests;
rather than multiple protests occurring concurrently, we may have recorded a protest
in our dataset that is also present in another dataset.

So it seems that there are a fair number of duplicates occurring if we don't
have a date offset, but once we add one (of any days) that pretty much solves
the data quality issue.

That being said, the likely larger problem with the CCC data is that it's only 
available after 2017, so it may not be relevant even after we become satisfied
with the deduped match process. This can be refined a little bit by adding in 
Elephrame data on BLM protests, but we've had problems there already, and the topic 
differences mean we can't pretend we have complete data.

# Maps and related things

```{r maps, message = FALSE, warning = FALSE}
county_sf <- counties(keep_zipped_shapefile = TRUE, progress_bar = FALSE) |> 
  select(fips = GEOID)
state_sf <- states(progress_bar = FALSE) |> 
  filter(!(NAME %in% c("Hawaii", "Puerto Rico", "American Samoa", 
                       "United States Virgin Islands", 
                       "Commonwealth of the Northern Mariana Islands",
                       "Alaska", "Guam"))) |> 
  select(state_fips = GEOID)
us_sf <- state_sf |> 
  st_union()
```

```{r mpeds_map}

mpeds_sf |> 
  st_transform(st_crs(county_sf)) |>
  mutate(geometry = st_jitter(geometry, factor = 0.005)) |> 
  ggplot() + 
  geom_sf(data = us_sf, fill = "white", color = "gray") + 
  geom_sf(size = 0.1, alpha = 0.2) + 
  lims(
    x = c(-130, -60),
    y = c(20, 55)
  ) +
  labs(
    title = "Spread of canonical events and geocoded locations",
    subtitle = "Locations jittered slightly, by 0.005*bounding box diagonal.",
    caption = "Alaska, Hawaii, a few other locations with only a\nfew protests excluded in this map only."
  ) + 
  theme_void() + 
  theme(text = element_text(family = "Lato"),
        plot.title = element_text(size = 20))
```

# Investigating specific movements: Mizzou and Quebec solidarity protests


```{r mizzou, warning = FALSE}
tar_load(canonical_event_relationship)

mizzou_umbrella_id <- mpeds |>
  filter(key == "Umbrella_Mizzou_Anti-Racism_2015_Oct-Nov") |> 
  pull(canonical_id)

mizzou_events <- canonical_event_relationship |> 
  filter(canonical_id2 == mizzou_umbrella_id) 
  
mizzou_by_type <- mizzou_events |> 
  mutate(relationship_type = paste0(str_to_title(relationship_type), " events only")) |> 
  count(stat = relationship_type) 
  
tribble(~stat, ~n,
        "Total number of links", nrow(mizzou_events),
        "Unique events", length(unique(mizzou_events$canonical_id1))) |> 
  bind_rows(mizzou_by_type) |> 
  rename("Statistics for Mizzou protests" = stat) |> 
  kable()
```
The discrepancy between the total number of links from the original Mizzou event to the 
total number of unique events comes from some events being both campaign events and 
counterprotest events, or campaign events and solidarity events. 

```{r mizzou_map}
tar_load(geo)
tar_load(canada_province_shapes)

mizzou_sf <- mizzou_events |> 
  # joining on `mpeds` and not `mpeds_sf` because we want coords of counties/CMAs,
  # not exactly where protests occurred (which is more granular)
  left_join(mpeds, by = c("canonical_id1" = "canonical_id")) |> 
  # Some events have been marked as both campaign and counterprotest/solidarity,
  # so they show up twice, but we only need one occurrence (and it doesn't
  # matter which, for this viz)
  group_by(canonical_id1) |> 
  slice_head(n = 1) |> 
  group_by(geoid) |> 
  count() |> 
  ungroup() |> 
  left_join(geo, by = "geoid") |> 
  mutate(geometry = st_centroid(geometry)) |> 
  st_as_sf(crs = st_crs(geo)) 

county_labels <- fips_codes |> 
  mutate(fips = paste0(state_code, county_code),
         name = str_wrap(paste0(county, ", ", state_name), 20)) |> 
  select(fips, name)

ggplot(mizzou_sf) +
  geom_sf(data = us_sf) +
  geom_sf(data = canada_province_shapes) +
  geom_sf(aes(size = n), alpha = 0.5) + 
  labs(
    title = "Spread of events within the Mizzou umbrella",
  ) + 
  scale_size(range = c(2, 8)) +
  scale_y_continuous(limits = c(24, 50)) + 
  scale_x_continuous(limits = c(-130, -60)) + 
  theme(
    axis.text = element_blank(),
    axis.ticks = element_blank(),
  )

mizzou_events |> 
  left_join(mpeds, by = c("canonical_id1" = "canonical_id")) |> 
  mutate(date = start_date) |> 
  group_by(date) |> 
  count() |> 
  ggplot(aes(x = date, y = n)) + 
  geom_line() + 
  geom_vline(xintercept = as.Date("2015-08-26"), color = "red") +
  annotate(geom = "text", label = "Mizzou grad student\nstrike start date",
           color = "red", x = as.Date("2015-09-12"), y = 10) + 
  scale_x_date(date_labels = "%b %y", date_breaks = "1 month") + 
  labs(
    x = "Date",
    y = "Number of canonical events starting on date",
    title = "Mizzou solidarity protest occurrences over time"
  )
  

```

```{r quebec}
quebec_events <- canonical_event_relationship |> 
  filter(canonical_id2 %in% c(2939, 2551)) 
  
quebec_by_type  <- quebec_events |> 
  mutate(relationship_type = paste0(str_to_title(relationship_type), " events only")) |> 
  count(stat = relationship_type) 
  
tribble(~stat, ~n,
        "Total number of links", nrow(quebec_events),
        "Unique events", length(unique(quebec_events$canonical_id1))) |> 
  bind_rows(quebec_by_type) |> 
  rename("Statistics for Quebec protests" = stat) |> 
  kable()

quebec_sf <- quebec_events |> 
  left_join(mpeds_sf, by = c("canonical_id1" = "canonical_id")) |> 
  st_as_sf() |> 
  group_by(geoid) |> 
  count() |> 
  ungroup() 

top_quebec <- quebec_sf |> 
  drop_na() |> 
  arrange(desc(n)) |> 
  slice_head(n = 5) 

ggplot(quebec_sf) +
  geom_sf(data = us_sf) +
  geom_sf(data = canada_province_shapes) +
  geom_sf(aes(size = n), alpha = 0.5) + 
  labs(
    title = "Spread of Quebec solidarity events",
  ) + 
  scale_size(range = c(2, 8)) + 
  theme(
    axis.text = element_blank(),
    axis.ticks = element_blank(),
  )

quebec_events |> 
  left_join(mpeds, by = c("canonical_id1" = "canonical_id")) |> 
  mutate(date = floor_date(start_date, "1 week")) |> 
  group_by(date) |> 
  count() |> 
  ggplot(aes(x = date, y = n)) + 
  geom_bar(stat = "identity") + 
  scale_x_date(date_labels = "%b %y", date_breaks = "5 months") + 
  labs(
    x = "Date",
    y = "Number of canonical events starting on date",
    title = "Quebec protest occurrences over time"
  )
  

```
